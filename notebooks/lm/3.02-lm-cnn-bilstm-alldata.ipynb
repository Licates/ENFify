{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-27T20:22:31.51238Z","iopub.status.busy":"2024-09-27T20:22:31.511447Z","iopub.status.idle":"2024-09-27T20:22:44.263059Z","shell.execute_reply":"2024-09-27T20:22:44.261985Z","shell.execute_reply.started":"2024-09-27T20:22:31.512309Z"},"trusted":true},"outputs":[],"source":["# %load_ext autoreload\n","# %autoreload 2\n","# !pip install torchsummary"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T20:22:44.265359Z","iopub.status.busy":"2024-09-27T20:22:44.265023Z","iopub.status.idle":"2024-09-27T20:22:47.115506Z","shell.execute_reply":"2024-09-27T20:22:47.11453Z","shell.execute_reply.started":"2024-09-27T20:22:44.265313Z"},"trusted":true},"outputs":[],"source":["import pickle\n","from pathlib import Path\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import RobustScaler\n","from torch.utils.data import DataLoader, SubsetRandomSampler, TensorDataset\n","from tqdm.notebook import tqdm\n","\n","# Ensure reproducibility\n","SEED = 0\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","\n","# Define data directory based on environment\n","DATA_DIR_CARIOCA_FREQS_10s = Path(\"/kaggle/input/carioca-freqs-10s-cnn-bilstm\")\n","DATA_DIR_SYNTH_FREQS_10s = Path(\"/kaggle/input/synthetic-variety-freqs-10s-cnn-bilstm\")\n","DATA_DIR_WHUREF_FREQS_10s = Path(\"/kaggle/input/whuref-freqs-10s-cnn-bilstm\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T20:22:47.117896Z","iopub.status.busy":"2024-09-27T20:22:47.116985Z","iopub.status.idle":"2024-09-27T20:22:47.15584Z","shell.execute_reply":"2024-09-27T20:22:47.154823Z","shell.execute_reply.started":"2024-09-27T20:22:47.117849Z"},"trusted":true},"outputs":[],"source":["# Use CUDA if a GPU is available\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n","print(\"Using device\", device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T20:22:47.158146Z","iopub.status.busy":"2024-09-27T20:22:47.157835Z","iopub.status.idle":"2024-09-27T20:22:47.166511Z","shell.execute_reply":"2024-09-27T20:22:47.165669Z","shell.execute_reply.started":"2024-09-27T20:22:47.158113Z"},"trusted":true},"outputs":[],"source":["# Hyperparameters\n","NUM_EPOCHS = 200\n","BATCH_SIZE = 64\n","LEARNING_RATE = 0.00001\n","TEST_SIZE = 0.2\n","\n","NAME = \"cnn_bilstm_alldata\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T20:22:47.168423Z","iopub.status.busy":"2024-09-27T20:22:47.167882Z","iopub.status.idle":"2024-09-27T20:22:47.195239Z","shell.execute_reply":"2024-09-27T20:22:47.1944Z","shell.execute_reply.started":"2024-09-27T20:22:47.168387Z"},"trusted":true},"outputs":[],"source":["class CNNSpatialExtractor(nn.Module):\n","    def __init__(self, input_size):\n","        super(CNNSpatialExtractor, self).__init__()\n","        # Convolution layers with padding to preserve spatial dimensions\n","        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n","        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        \n","        final_size = input_size // 8\n","        \n","        # Compute the flattened size after convolutions and pooling\n","        self.fc1 = nn.Linear(64 * final_size * final_size, 1024)  # Flattened size: 64 channels * 5x5\n","        self.fc2 = nn.Linear(1024, 256)         # Second fully connected layer\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))  # Output size: (22x22)\n","        x = self.pool(F.relu(self.conv2(x)))  # Output size: (11x11)\n","        x = self.pool(F.relu(self.conv3(x)))  # Output size: (5x5)\n","        x = x.view(x.size(0), -1)  # Flatten the output\n","        x = F.relu(self.fc1(x))   # First fully connected layer\n","        x = F.relu(self.fc2(x))   # Second fully connected layer\n","        return x\n","\n","\n","# BiLSTM block for temporal feature extraction\n","class DeepBiLSTMTemporalExtractor(nn.Module):\n","    def __init__(self, input_size=85, hidden_size=85, num_layers=2):\n","        super(DeepBiLSTMTemporalExtractor, self).__init__()\n","        \n","        # First BiLSTM module\n","        self.bilstm1 = nn.LSTM(input_size, hidden_size, num_layers=1, bidirectional=True, batch_first=True)\n","        self.norm1 = nn.LayerNorm(hidden_size * 2)  # Normalization layer for the first BiLSTM\n","        \n","        # Second BiLSTM module\n","        self.bilstm2 = nn.LSTM(hidden_size * 2, hidden_size, num_layers=1, bidirectional=True, batch_first=True)\n","        self.norm2 = nn.LayerNorm(hidden_size * 2)  # Normalization layer for the second BiLSTM\n","        \n","        # Fully connected layers\n","        self.fc1 = nn.Linear(hidden_size * 2, 512)  # First fully connected layer (input: hidden_size*2, output: 512)\n","        self.fc2 = nn.Linear(512, 256)  # Second fully connected layer (input: 512, output: 256)\n","\n","    def forward(self, x):\n","        # First BiLSTM layer\n","        lstm_out1, _ = self.bilstm1(x)\n","        lstm_out1 = self.norm1(lstm_out1)  # Apply normalization\n","        lstm_out1 = F.relu(lstm_out1)  # Apply ReLU activation\n","        \n","        # Second BiLSTM layer\n","        lstm_out2, _ = self.bilstm2(lstm_out1)\n","        lstm_out2 = self.norm2(lstm_out2)  # Apply normalization\n","        lstm_out2 = F.relu(lstm_out2)  # Apply ReLU activation\n","        \n","        # Get the last time step output from the sequence\n","        x = lstm_out2[:, -1, :]  # Shape (batch_size, hidden_size * 2)\n","        \n","        # Fully connected layers\n","        x = F.relu(self.fc1(x))  # First fully connected layer\n","        x = F.relu(self.fc2(x))  # Second fully connected layer\n","        \n","        return x\n","\n","\n","class SpatioTemporalAttention(nn.Module):\n","    def __init__(self, spatial_feature_size, temporal_feature_size):\n","        super(SpatioTemporalAttention, self).__init__()\n","        \n","        self.concat_size = spatial_feature_size + temporal_feature_size   # Size of concatenated features\n","\n","        # Fully connected layers for feature compression and transformation\n","        self.fc1 = nn.Linear(self.concat_size, self.concat_size)\n","        self.fc2 = nn.Linear(self.concat_size, self.concat_size // 8)\n","        self.fc3 = nn.Linear(self.concat_size // 8, self.concat_size)\n","\n","        # Fully connected layer for attention weights\n","        self.fc4 = nn.Linear(self.concat_size, self.concat_size)\n","    \n","    def forward(self, spatial_feat, temporal_feat):\n","        # Concatenate spatial and temporal features\n","        combined_feat = torch.cat((spatial_feat, temporal_feat), dim=1)  # Shape: (batch_size, concat_size)\n","\n","        # Apply compression layers with ReLU activation\n","        x = F.relu(self.fc1(combined_feat))\n","        x = F.relu(self.fc2(x))\n","        x = F.relu(self.fc3(x))\n","\n","        # Compute attention weights using sigmoid activation\n","        attention_weights = torch.sigmoid(self.fc4(x))  # Shape: (batch_size, concat_size)\n","\n","        # Element-wise multiplication to fuse features with attention weights\n","        fused_features = combined_feat * attention_weights  # Shape: (batch_size, concat_size)\n","\n","        return fused_features\n","\n","\n","class ClassificationNetwork(nn.Module):\n","    def __init__(self, input_size):\n","        super(ClassificationNetwork, self).__init__()\n","        \n","        # Define fully connected layers\n","        self.fc1 = nn.Linear(input_size, 400)\n","        self.fc2 = nn.Linear(400, 256)\n","        self.fc3 = nn.Linear(256, 128)\n","        self.fc4 = nn.Linear(128, 32)\n","        \n","        # Define dropout layer\n","        self.dropout = nn.Dropout(0.2)\n","        \n","        # Define final fully connected layer for output\n","        self.fc5 = nn.Linear(32, 1)  # Output is binary classification, so 2 neurons\n","\n","    def forward(self, x):\n","        # Pass through the first fully connected layer and apply Leaky ReLU\n","        x = F.leaky_relu(self.fc1(x))\n","        x = self.dropout(x)\n","        \n","        # Pass through the second fully connected layer and apply Leaky ReLU\n","        x = F.leaky_relu(self.fc2(x))\n","        x = self.dropout(x)\n","        \n","        # Pass through the third fully connected layer and apply Leaky ReLU\n","        x = F.leaky_relu(self.fc3(x))\n","        x = self.dropout(x)\n","        \n","        # Pass through the fourth fully connected layer and apply Leaky ReLU\n","        x = F.leaky_relu(self.fc4(x))\n","        x = self.dropout(x)\n","        \n","        # Output layer with softmax activation\n","        x = self.fc5(x)\n","        #x = F.softmax(x, dim=1)  # Use log_softmax for numerical stability\n","        \n","        return x\n","\n","# Complete Network\n","class ParallelCNNBiLSTM(nn.Module):\n","    def __init__(self, temporal_input_size, spatial_input_size):\n","        super(ParallelCNNBiLSTM, self).__init__()\n","        self.spatial_extractor = CNNSpatialExtractor(input_size = spatial_input_size)\n","        self.temporal_extractor = DeepBiLSTMTemporalExtractor(input_size=temporal_input_size, hidden_size=temporal_input_size)\n","        self.attention = SpatioTemporalAttention(256, 256)\n","        self.classifier = ClassificationNetwork(input_size=2 * 256)\n","\n","    def forward(self, spatial_input, temporal_input):\n","        spatial_features = self.spatial_extractor(spatial_input)\n","        temporal_features = self.temporal_extractor(temporal_input)\n","        fused_features = self.attention(spatial_features, temporal_features)\n","        output = self.classifier(fused_features)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T20:22:47.196824Z","iopub.status.busy":"2024-09-27T20:22:47.196406Z","iopub.status.idle":"2024-09-27T20:22:47.210226Z","shell.execute_reply":"2024-09-27T20:22:47.209289Z","shell.execute_reply.started":"2024-09-27T20:22:47.196781Z"},"trusted":true},"outputs":[],"source":["# class EarlyStopping:\n","#     def __init__(self, patience=10, min_delta=0):\n","#         self.patience = patience\n","#         self.min_delta = min_delta\n","#         self.counter = 0\n","#         self.best_loss = None\n","#         self.early_stop = False\n","\n","#     def __call__(self, val_loss):\n","#         if self.best_loss is None:\n","#             self.best_loss = val_loss\n","#         elif val_loss > self.best_loss - self.min_delta:\n","#             self.counter += 1\n","#             if self.counter >= self.patience:\n","#                 self.early_stop = True\n","#         else:\n","#             self.best_loss = val_loss\n","#             self.counter = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T20:22:47.212009Z","iopub.status.busy":"2024-09-27T20:22:47.211517Z","iopub.status.idle":"2024-09-27T20:22:48.218903Z","shell.execute_reply":"2024-09-27T20:22:48.217978Z","shell.execute_reply.started":"2024-09-27T20:22:47.211975Z"},"trusted":true},"outputs":[],"source":["spatial_input_size = 46  # Height and width for CNN input\n","temporal_input_size = 25  # Input size for LSTM\n","sequence_length = 85  # Temporal sequence length\n","\n","# Create model\n","model = ParallelCNNBiLSTM(temporal_input_size=temporal_input_size, spatial_input_size=spatial_input_size).to(device)\n","\n","# Print summary using torchinfo\n","# from torchinfo import summary\n","# summary(model, input_size=[(BATCH_SIZE, 1, spatial_input_size, spatial_input_size), (BATCH_SIZE, sequence_length, temporal_input_size)])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T20:22:48.220931Z","iopub.status.busy":"2024-09-27T20:22:48.220534Z","iopub.status.idle":"2024-09-27T20:23:04.400587Z","shell.execute_reply":"2024-09-27T20:23:04.39957Z","shell.execute_reply.started":"2024-09-27T20:22:48.220887Z"},"trusted":true},"outputs":[],"source":["###...............................Load the data...............................###\n","data_spatial_synth = np.load(DATA_DIR_SYNTH_FREQS_10s / \"synthetic_spatial_freqs.npy\", allow_pickle=True)\n","data_temporal_synth = np.load(DATA_DIR_SYNTH_FREQS_10s / \"synthetic_temporal_freqs.npy\", allow_pickle=True)\n","labels_synth = np.load(DATA_DIR_SYNTH_FREQS_10s / \"synthetic_labels_freqs.npy\", allow_pickle=True)\n","\n","data_spatial_whuref = np.load(DATA_DIR_WHUREF_FREQS_10s / \"whu_ref_spatial_freqs.npy\", allow_pickle=True)\n","data_temporal_whuref = np.load(DATA_DIR_WHUREF_FREQS_10s / \"whu_ref_temporal_freqs.npy\", allow_pickle=True)\n","labels_whuref = np.load(DATA_DIR_WHUREF_FREQS_10s / \"whu_ref_labels_freqs.npy\", allow_pickle=True)\n","\n","data_spatial_carioca = np.load(DATA_DIR_CARIOCA_FREQS_10s / \"carioca_spatial_freqs.npy\", allow_pickle=True)\n","data_temporal_carioca = np.load(DATA_DIR_CARIOCA_FREQS_10s / \"carioca_temporal_freqs.npy\", allow_pickle=True)\n","labels_carioca = np.load(DATA_DIR_CARIOCA_FREQS_10s / \"carioca_labels_freqs.npy\", allow_pickle=True)\n","\n","\n","# Concatenate\n","data_spatial = np.concatenate((data_spatial_synth, data_spatial_whuref, data_spatial_carioca), axis=0)\n","data_temporal = np.concatenate((data_temporal_synth, data_temporal_whuref, data_temporal_carioca), axis=0)\n","labels = np.concatenate((labels_synth, labels_whuref, labels_carioca), axis=0)\n","dset = np.concatenate(np.zeros(len(labels_synth)), np.ones(len(labels_whuref)), np.ones(len(labels_carioca)) * 2)\n","stratify = np.hstack((labels, dset))\n","\n","\n","###...............................Normalize...............................###\n","scaler_spatial = RobustScaler() # Apply RobustScaler\n","spatial_shape = data_spatial.shape\n","data_spatial_reshaped = data_spatial.reshape(data_spatial.shape[0], -1) # Reshape data for RobustScaler (n_samples, n_features) format\n","data_spatial = scaler_spatial.fit_transform(data_spatial_reshaped)\n","data_spatial = data_spatial.reshape(spatial_shape) # Reshape back to original shape\n","with open(f\"{NAME}_spatial_scaler.pkl\", \"wb\") as f:\n","    pickle.dump(scaler_spatial, f)\n","\n","scaler_temporal = RobustScaler() # Apply RobustScaler\n","temporal_shape = data_temporal.shape\n","data_temporal_reshaped = data_temporal.reshape(data_temporal.shape[0], -1) # Reshape data for RobustScaler (n_samples, n_features) format\n","data_temporal = scaler_temporal.fit_transform(data_temporal_reshaped)\n","data_temporal = data_temporal.reshape(temporal_shape) # Reshape back to original shape\n","with open(f\"{NAME}_temporal_scaler.pkl\", \"wb\") as f:\n","    pickle.dump(scaler_temporal, f)\n","\n","# Add channel dimension\n","data_spatial = data_spatial[:, np.newaxis, :, :]\n","\n","###...............................Split into Training Validation and Test data...............................###\n","X_spatial_train, X_spatial_test, X_temporal_train, X_temporal_test, stratify_train, stratify_test = (\n","    train_test_split(\n","        data_spatial,\n","        data_temporal,\n","        stratify,\n","        test_size=TEST_SIZE,\n","        random_state=SEED,\n","        shuffle=True,\n","        stratify=stratify,\n","    )\n",")\n","y_train = stratify_train[:, 0]\n","y_test = stratify_test[:, 0]\n","dset_test = stratify_test[:, 1]\n","\n","X_spatial_train, X_spatial_val, X_temporal_train, X_temporal_val, y_train, y_val = (\n","    train_test_split(\n","        X_spatial_train,\n","        X_temporal_train,\n","        y_train,\n","        test_size=TEST_SIZE,\n","        random_state=SEED,\n","        shuffle=True,\n","        stratify=stratify_train,\n","    )\n",")\n","\n","\n","###..................................Convert Data Tensors and move to the GPU..................................###\n","# Convert to tensors and move to device\n","X_spatial_train = torch.tensor(X_spatial_train, dtype=torch.float32).to(device)\n","X_spatial_val = torch.tensor(X_spatial_val, dtype=torch.float32).to(device)\n","X_spatial_test = torch.tensor(X_spatial_test, dtype=torch.float32).to(device)\n","\n","X_temporal_train = torch.tensor(X_temporal_train, dtype=torch.float32).to(device)\n","X_temporal_val = torch.tensor(X_temporal_val, dtype=torch.float32).to(device)\n","X_temporal_test = torch.tensor(X_temporal_test, dtype=torch.float32).to(device)\n","\n","y_train = torch.LongTensor(y_train).to(device)\n","y_val = torch.LongTensor(y_val).to(device)\n","y_test = torch.LongTensor(y_test).to(device)\n","\n","\n","###.....................Create TensorDatasets for spatial and temporal inputs.....................###\n","train_dataset = TensorDataset(X_spatial_train, X_temporal_train, y_train)\n","val_dataset = TensorDataset(X_spatial_val, X_temporal_val, y_val)\n","test_dataset = TensorDataset(X_spatial_test, X_temporal_test, y_test)\n","\n","# Data loaders\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","def create_loader(dataset, dset_ids, target_dset_id, batch_size):\n","    indices = (dset_ids == target_dset_id).nonzero(as_tuple=True)[0]\n","    sampler = SubsetRandomSampler(indices)\n","    return DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n","test_loader_synth = create_loader(test_dataset, dset, 0, BATCH_SIZE)\n","test_loader_whuref = create_loader(test_dataset, dset, 1, BATCH_SIZE)\n","test_loader_carioca = create_loader(test_dataset, dset, 2, BATCH_SIZE)\n","\n","\n","###.........................Check label distribution for training.........................###\n","unique, counts = np.unique(y_train.cpu(), return_counts=True)\n","class_distribution = dict(zip(unique, counts))\n","print(f\"y_train distribution: {class_distribution}\")\n","\n","unique, counts = np.unique(y_val.cpu(), return_counts=True)\n","class_distribution = dict(zip(unique, counts))\n","print(f\"y_val distribution: {class_distribution}\")\n","\n","unique, counts = np.unique(y_test.cpu(), return_counts=True)\n","class_distribution = dict(zip(unique, counts))\n","print(f\"y_test distribution: {class_distribution}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T20:23:04.402406Z","iopub.status.busy":"2024-09-27T20:23:04.401961Z","iopub.status.idle":"2024-09-27T20:23:05.309459Z","shell.execute_reply":"2024-09-27T20:23:05.308651Z","shell.execute_reply.started":"2024-09-27T20:23:04.402334Z"},"trusted":true},"outputs":[],"source":["# Initialize loss function and optimizer\n","criterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss for binary classification\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  # Adam optimizer"]},{"cell_type":"markdown","metadata":{},"source":["# TRAINING"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T20:23:05.313643Z","iopub.status.busy":"2024-09-27T20:23:05.313002Z","iopub.status.idle":"2024-09-27T20:26:47.44696Z","shell.execute_reply":"2024-09-27T20:26:47.44609Z","shell.execute_reply.started":"2024-09-27T20:23:05.313604Z"},"trusted":true},"outputs":[],"source":["# Initialize EarlyStopping object\n","# early_stopping = EarlyStopping(patience=100, min_delta=0.01)\n","\n","# Training and validation loop\n","train_losses = []\n","val_losses = []\n","train_accuracies = []\n","val_accuracies = []\n","\n","for epoch in tqdm(range(NUM_EPOCHS), desc=\"Training Progress\"):\n","    # Training\n","    model.train()\n","    train_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","    for spatial_inputs, temporal_inputs, labels in train_loader:  # Assuming data loader returns spatial and temporal inputs\n","        optimizer.zero_grad()\n","        outputs = model(spatial_inputs, temporal_inputs)\n","        \n","        # Ensure labels have the same shape as outputs\n","        labels = labels.unsqueeze(1).float()  # Convert [64] to [64, 1]\n","\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","\n","        # Use sigmoid to get predictions for binary classification\n","        predictions = torch.sigmoid(outputs)\n","        predicted_labels = (predictions > 0.5).float()  # Convert to binary predictions\n","        \n","        total_train += labels.size(0)\n","        correct_train += (predicted_labels == labels).sum().item()\n","\n","    train_loss /= len(train_loader)\n","    train_losses.append(train_loss)\n","    train_accuracy = correct_train / total_train\n","    train_accuracies.append(train_accuracy)\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0.0\n","    correct_val = 0\n","    total_val = 0\n","    with torch.no_grad():\n","        for spatial_inputs, temporal_inputs, labels in val_loader:  # Assuming data loader returns spatial and temporal inputs\n","            outputs = model(spatial_inputs, temporal_inputs)\n","            \n","            # Ensure labels have the same shape as outputs\n","            labels = labels.unsqueeze(1).float()  # Convert [64] to [64, 1]\n","\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","            # Use sigmoid to get predictions for binary classification\n","            predictions = torch.sigmoid(outputs)\n","            predicted_labels = (predictions > 0.5).float()  # Convert to binary predictions\n","\n","            total_val += labels.size(0)\n","            correct_val += (predicted_labels == labels).sum().item()\n","\n","    val_loss /= len(val_loader)\n","    val_losses.append(val_loss)\n","    val_accuracy = correct_val / total_val\n","    val_accuracies.append(val_accuracy)\n","\n","    tqdm.write(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n","    \n","    # # Check early stopping condition\n","    # early_stopping(val_loss)\n","    # if early_stopping.early_stop:\n","    #     print(\"Early stopping\")\n","    #     break"]},{"cell_type":"markdown","metadata":{},"source":["# TESTING"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T20:26:47.448504Z","iopub.status.busy":"2024-09-27T20:26:47.448189Z","iopub.status.idle":"2024-09-27T20:26:47.595911Z","shell.execute_reply":"2024-09-27T20:26:47.595015Z","shell.execute_reply.started":"2024-09-27T20:26:47.448471Z"},"trusted":true},"outputs":[],"source":["## Synthetische Daten\n","\n","# Testing phase\n","model.eval()\n","test_loss = 0.0\n","correct = 0\n","total = 0\n","true_positive = 0\n","false_positive = 0\n","false_negative = 0\n","true_negative = 0  # For untampered sample recall\n","\n","# Confusion matrix elements\n","confusion_matrix = torch.zeros(2, 2)  # 2x2 for binary classification\n","\n","with torch.no_grad():\n","    for spatial_inputs, temporal_inputs, labels in test_loader_synth:  # Assuming data loader returns spatial and temporal inputs\n","        outputs = model(spatial_inputs, temporal_inputs)\n","        \n","        labels = labels.unsqueeze(1).float()  # Adjust labels to match the output dimension\n","        \n","        loss = criterion(outputs, labels)\n","        test_loss += loss.item()\n","        \n","        predictions = torch.sigmoid(outputs)\n","        predicted_labels = (predictions > 0.5).float()  # Convert to binary labels\n","        \n","        total += labels.size(0)\n","        correct += (predicted_labels == labels).sum().item()\n","        \n","        # Update confusion matrix\n","        for t, p in zip(labels.view(-1), predicted_labels.view(-1)):  # Iterate over true and predicted labels\n","            confusion_matrix[int(t.long()), int(p.long())] += 1  # Fill confusion matrix\n","        \n","        # Calculate True Positives, False Positives, False Negatives, and True Negatives\n","        true_positive += ((predicted_labels == 1) & (labels == 1)).sum().item()\n","        false_positive += ((predicted_labels == 1) & (labels == 0)).sum().item()\n","        false_negative += ((predicted_labels == 0) & (labels == 1)).sum().item()\n","        true_negative += ((predicted_labels == 0) & (labels == 0)).sum().item()\n","\n","test_loss /= len(test_loader_synth)\n","test_accuracy = correct / total\n","\n","# Calculate Precision\n","if true_positive + false_positive > 0:\n","    precision = true_positive / (true_positive + false_positive)\n","else:\n","    precision = 0.0  # Avoid division by zero\n","\n","# Calculate Recall for tampered samples (positive class)\n","if true_positive + false_negative > 0:\n","    recall_tampered = true_positive / (true_positive + false_negative)\n","else:\n","    recall_tampered = 0.0  # Avoid division by zero\n","\n","# Calculate Recall for untampered samples (negative class)\n","if true_negative + false_positive > 0:\n","    recall_untampered = true_negative / (true_negative + false_positive)\n","else:\n","    recall_untampered = 0.0  # Avoid division by zero\n","\n","# Print results\n","print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Precision: {precision:.4f}, Test Recall (tampered): {recall_tampered:.4f}, Test Recall (untampered): {recall_untampered:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T20:26:47.59729Z","iopub.status.busy":"2024-09-27T20:26:47.596995Z","iopub.status.idle":"2024-09-27T20:26:49.462073Z","shell.execute_reply":"2024-09-27T20:26:49.461142Z","shell.execute_reply.started":"2024-09-27T20:26:47.597258Z"},"trusted":true},"outputs":[],"source":["# Plot the training and validation losses and accuracies\n","plt.figure(figsize=(12, 6))\n","\n","# Plotting Training and Validation Loss\n","plt.subplot(1, 2, 1)\n","plt.plot(train_losses, label=\"Train Loss\", alpha=0.7)\n","plt.plot(val_losses, label=\"Validation Loss\", alpha=0.7)\n","plt.xlabel(\"Epoche\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.title(\"Training and Validation Loss\")\n","\n","# Plotting Training and Validation Accuracy\n","plt.subplot(1, 2, 2)\n","plt.plot(train_accuracies, label=\"Train Accuracy\", alpha=0.7)\n","plt.plot(val_accuracies, label=\"Validation Accuracy\", alpha=0.7)\n","plt.xlabel(\"Epoche\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend()\n","plt.title(\"Training und Validation Accuracy\")\n","plt.savefig('Valdidation_accuracy_and_loss_cnn-bilstm_all_freqs.pdf', dpi=300)\n","plt.tight_layout()\n","plt.show()\n","\n","\n","# Convert confusion matrix to numpy for plotting\n","cm = confusion_matrix.numpy()\n","\n","# Plotting the confusion matrix using seaborn\n","plt.figure(figsize=(6, 4))\n","sns.heatmap(cm, annot=True, fmt='.0f', cmap='Blues', xticklabels=['Ungeschnitten', 'Geschnitten'], yticklabels=['Ungeschnitten', 'Geschnitten'])\n","plt.xlabel('Vorhergesagtes Label')\n","plt.ylabel('Wahres Label')\n","plt.title('Confusion Matrix')\n","plt.savefig('synth_confusion_matrix_cnn-bilstm_all_freqs.pdf', dpi=300)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T20:26:49.463612Z","iopub.status.busy":"2024-09-27T20:26:49.463152Z","iopub.status.idle":"2024-09-27T20:26:49.558853Z","shell.execute_reply":"2024-09-27T20:26:49.557977Z","shell.execute_reply.started":"2024-09-27T20:26:49.463579Z"},"trusted":true},"outputs":[],"source":["## WHU Ref Data\n","\n","# Testing phase\n","model.eval()\n","test_loss = 0.0\n","correct = 0\n","total = 0\n","true_positive = 0\n","false_positive = 0\n","false_negative = 0\n","true_negative = 0  # For untampered sample recall\n","\n","# Confusion matrix elements\n","confusion_matrix = torch.zeros(2, 2)  # 2x2 for binary classification\n","\n","with torch.no_grad():\n","    for spatial_inputs, temporal_inputs, labels in test_loader_whuref:  # Assuming data loader returns spatial and temporal inputs\n","        outputs = model(spatial_inputs, temporal_inputs)\n","        \n","        labels = labels.unsqueeze(1).float()  # Adjust labels to match the output dimension\n","        \n","        loss = criterion(outputs, labels)\n","        test_loss += loss.item()\n","        \n","        predictions = torch.sigmoid(outputs)\n","        predicted_labels = (predictions > 0.5).float()  # Convert to binary labels\n","        \n","        total += labels.size(0)\n","        correct += (predicted_labels == labels).sum().item()\n","        \n","        # Update confusion matrix\n","        for t, p in zip(labels.view(-1), predicted_labels.view(-1)):  # Iterate over true and predicted labels\n","            confusion_matrix[int(t.long()), int(p.long())] += 1  # Fill confusion matrix\n","        \n","        # Calculate True Positives, False Positives, False Negatives, and True Negatives\n","        true_positive += ((predicted_labels == 1) & (labels == 1)).sum().item()\n","        false_positive += ((predicted_labels == 1) & (labels == 0)).sum().item()\n","        false_negative += ((predicted_labels == 0) & (labels == 1)).sum().item()\n","        true_negative += ((predicted_labels == 0) & (labels == 0)).sum().item()\n","\n","test_loss /= len(test_loader_whuref)\n","test_accuracy = correct / total\n","\n","# Calculate Precision\n","if true_positive + false_positive > 0:\n","    precision = true_positive / (true_positive + false_positive)\n","else:\n","    precision = 0.0  # Avoid division by zero\n","\n","# Calculate Recall for tampered samples (positive class)\n","if true_positive + false_negative > 0:\n","    recall_tampered = true_positive / (true_positive + false_negative)\n","else:\n","    recall_tampered = 0.0  # Avoid division by zero\n","\n","# Calculate Recall for untampered samples (negative class)\n","if true_negative + false_positive > 0:\n","    recall_untampered = true_negative / (true_negative + false_positive)\n","else:\n","    recall_untampered = 0.0  # Avoid division by zero\n","\n","# Print results\n","print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Precision: {precision:.4f}, Test Recall (tampered): {recall_tampered:.4f}, Test Recall (untampered): {recall_untampered:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T20:26:49.560164Z","iopub.status.busy":"2024-09-27T20:26:49.559865Z","iopub.status.idle":"2024-09-27T20:26:50.013869Z","shell.execute_reply":"2024-09-27T20:26:50.012916Z","shell.execute_reply.started":"2024-09-27T20:26:49.560132Z"},"trusted":true},"outputs":[],"source":["# Convert confusion matrix to numpy for plotting\n","cm = confusion_matrix.numpy()\n","\n","# Plotting the confusion matrix using seaborn\n","plt.figure(figsize=(6, 4))\n","sns.heatmap(cm, annot=True, fmt='.0f', cmap='Blues', xticklabels=['Ungeschnitten', 'Geschnitten'], yticklabels=['Ungeschnitten', 'Geschnitten'])\n","plt.xlabel('Vorhergesagtes Label')\n","plt.ylabel('Wahres Label')\n","plt.title('Confusion Matrix')\n","plt.savefig('whuref_confusion_matrix_cnn-bilstm_all_freqs.pdf', dpi=300)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T20:26:50.01601Z","iopub.status.busy":"2024-09-27T20:26:50.015455Z","iopub.status.idle":"2024-09-27T20:26:50.138197Z","shell.execute_reply":"2024-09-27T20:26:50.137071Z","shell.execute_reply.started":"2024-09-27T20:26:50.015957Z"},"trusted":true},"outputs":[],"source":["## Carioca Data\n","\n","# Testing phase\n","model.eval()\n","test_loss = 0.0\n","correct = 0\n","total = 0\n","true_positive = 0\n","false_positive = 0\n","false_negative = 0\n","true_negative = 0  # For untampered sample recall\n","\n","# Confusion matrix elements\n","confusion_matrix = torch.zeros(2, 2)  # 2x2 for binary classification\n","\n","with torch.no_grad():\n","    for spatial_inputs, temporal_inputs, labels in test_loader_carioca:  # Assuming data loader returns spatial and temporal inputs\n","        outputs = model(spatial_inputs, temporal_inputs)\n","        \n","        labels = labels.unsqueeze(1).float()  # Adjust labels to match the output dimension\n","        \n","        loss = criterion(outputs, labels)\n","        test_loss += loss.item()\n","        \n","        predictions = torch.sigmoid(outputs)\n","        predicted_labels = (predictions > 0.5).float()  # Convert to binary labels\n","        \n","        total += labels.size(0)\n","        correct += (predicted_labels == labels).sum().item()\n","        \n","        # Update confusion matrix\n","        for t, p in zip(labels.view(-1), predicted_labels.view(-1)):  # Iterate over true and predicted labels\n","            confusion_matrix[int(t.long()), int(p.long())] += 1  # Fill confusion matrix\n","        \n","        # Calculate True Positives, False Positives, False Negatives, and True Negatives\n","        true_positive += ((predicted_labels == 1) & (labels == 1)).sum().item()\n","        false_positive += ((predicted_labels == 1) & (labels == 0)).sum().item()\n","        false_negative += ((predicted_labels == 0) & (labels == 1)).sum().item()\n","        true_negative += ((predicted_labels == 0) & (labels == 0)).sum().item()\n","\n","test_loss /= len(test_loader_carioca)\n","test_accuracy = correct / total\n","\n","# Calculate Precision\n","if true_positive + false_positive > 0:\n","    precision = true_positive / (true_positive + false_positive)\n","else:\n","    precision = 0.0  # Avoid division by zero\n","\n","# Calculate Recall for tampered samples (positive class)\n","if true_positive + false_negative > 0:\n","    recall_tampered = true_positive / (true_positive + false_negative)\n","else:\n","    recall_tampered = 0.0  # Avoid division by zero\n","\n","# Calculate Recall for untampered samples (negative class)\n","if true_negative + false_positive > 0:\n","    recall_untampered = true_negative / (true_negative + false_positive)\n","else:\n","    recall_untampered = 0.0  # Avoid division by zero\n","\n","# Print results\n","print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Precision: {precision:.4f}, Test Recall (tampered): {recall_tampered:.4f}, Test Recall (untampered): {recall_untampered:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T20:26:50.13959Z","iopub.status.busy":"2024-09-27T20:26:50.13926Z","iopub.status.idle":"2024-09-27T20:26:50.61947Z","shell.execute_reply":"2024-09-27T20:26:50.61855Z","shell.execute_reply.started":"2024-09-27T20:26:50.139556Z"},"trusted":true},"outputs":[],"source":["## Plot Carioca confusion matrix\n","# Convert confusion matrix to numpy for plotting\n","cm = confusion_matrix.numpy()\n","\n","# Plotting the confusion matrix using seaborn\n","plt.figure(figsize=(6, 4))\n","sns.heatmap(cm, annot=True, fmt='.0f', cmap='Blues', xticklabels=['Ungeschnitten', 'Geschnitten'], yticklabels=['Ungeschnitten', 'Geschnitten'])\n","plt.xlabel('Vorhergesagtes Label')\n","plt.ylabel('Wahres Label')\n","plt.title('Confusion Matrix')\n","plt.savefig('carioca_confusion_matrix_cnn-bilstm_all_freqs.pdf', dpi=300)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-27T20:26:50.621005Z","iopub.status.busy":"2024-09-27T20:26:50.620721Z","iopub.status.idle":"2024-09-27T20:26:50.649831Z","shell.execute_reply":"2024-09-27T20:26:50.64899Z","shell.execute_reply.started":"2024-09-27T20:26:50.620975Z"},"trusted":true},"outputs":[],"source":["# Save the model\n","torch.save(model.state_dict(), f\"{NAME}_model.pth\")\n","print(\"Model saved successfully!\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5728003,"sourceId":9428816,"sourceType":"datasetVersion"},{"datasetId":5766277,"sourceId":9480074,"sourceType":"datasetVersion"},{"datasetId":5766284,"sourceId":9480083,"sourceType":"datasetVersion"},{"datasetId":5766297,"sourceId":9480097,"sourceType":"datasetVersion"},{"datasetId":5770118,"sourceId":9485179,"sourceType":"datasetVersion"},{"datasetId":5770698,"sourceId":9485921,"sourceType":"datasetVersion"},{"datasetId":5771806,"sourceId":9487402,"sourceType":"datasetVersion"},{"datasetId":5771853,"sourceId":9487465,"sourceType":"datasetVersion"},{"datasetId":5773160,"sourceId":9489223,"sourceType":"datasetVersion"}],"dockerImageVersionId":30776,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
