{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9428816,"sourceType":"datasetVersion","datasetId":5728003},{"sourceId":9480074,"sourceType":"datasetVersion","datasetId":5766277},{"sourceId":9480083,"sourceType":"datasetVersion","datasetId":5766284},{"sourceId":9480097,"sourceType":"datasetVersion","datasetId":5766297},{"sourceId":9485179,"sourceType":"datasetVersion","datasetId":5770118},{"sourceId":9485921,"sourceType":"datasetVersion","datasetId":5770698},{"sourceId":9487402,"sourceType":"datasetVersion","datasetId":5771806},{"sourceId":9487465,"sourceType":"datasetVersion","datasetId":5771853},{"sourceId":9489223,"sourceType":"datasetVersion","datasetId":5773160},{"sourceId":122693,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":103256,"modelId":127486}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %load_ext autoreload\n# %autoreload 2\n!pip install torchsummary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchsummary import summary\nfrom tqdm.notebook import tqdm\nfrom sklearn.preprocessing import RobustScaler\nimport seaborn as sns\n\n# Ensure reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Define data directory based on environment\nDATA_DIR_CARIOCA_FREQS_10s = Path(\"/kaggle/input/carioca-freqs-10s-cnn-bilstm\")\nDATA_DIR_SYNTH_FREQS_10s = Path(\"/kaggle/input/synthetic-variety-freqs-10s-cnn-bilstm\")\nDATA_DIR_WHUREF_FREQS_10s = Path(\"/kaggle/input/whuref-freqs-10s-cnn-bilstm\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use CUDA if a GPU is available\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\nprint(\"Using device\", device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nNUM_EPOCHS = 200\nBATCH_SIZE = 64\nLEARNING_RATE = 0.00001\nTEST_SIZE = 0.2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNNSpatialExtractor(nn.Module):\n    def __init__(self, input_size):\n        super(CNNSpatialExtractor, self).__init__()\n        # Convolution layers with padding to preserve spatial dimensions\n        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        final_size = input_size // 8\n        \n        # Compute the flattened size after convolutions and pooling\n        self.fc1 = nn.Linear(64 * final_size * final_size, 1024)  # Flattened size: 64 channels * 5x5\n        self.fc2 = nn.Linear(1024, 256)         # Second fully connected layer\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))  # Output size: (22x22)\n        x = self.pool(F.relu(self.conv2(x)))  # Output size: (11x11)\n        x = self.pool(F.relu(self.conv3(x)))  # Output size: (5x5)\n        x = x.view(x.size(0), -1)  # Flatten the output\n        x = F.relu(self.fc1(x))   # First fully connected layer\n        x = F.relu(self.fc2(x))   # Second fully connected layer\n        return x\n\n\n# BiLSTM block for temporal feature extraction\nclass DeepBiLSTMTemporalExtractor(nn.Module):\n    def __init__(self, input_size=85, hidden_size=85, num_layers=2):\n        super(DeepBiLSTMTemporalExtractor, self).__init__()\n        \n        # First BiLSTM module\n        self.bilstm1 = nn.LSTM(input_size, hidden_size, num_layers=1, bidirectional=True, batch_first=True)\n        self.norm1 = nn.LayerNorm(hidden_size * 2)  # Normalization layer for the first BiLSTM\n        \n        # Second BiLSTM module\n        self.bilstm2 = nn.LSTM(hidden_size * 2, hidden_size, num_layers=1, bidirectional=True, batch_first=True)\n        self.norm2 = nn.LayerNorm(hidden_size * 2)  # Normalization layer for the second BiLSTM\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(hidden_size * 2, 512)  # First fully connected layer (input: hidden_size*2, output: 512)\n        self.fc2 = nn.Linear(512, 256)  # Second fully connected layer (input: 512, output: 256)\n\n    def forward(self, x):\n        # First BiLSTM layer\n        lstm_out1, _ = self.bilstm1(x)\n        lstm_out1 = self.norm1(lstm_out1)  # Apply normalization\n        lstm_out1 = F.relu(lstm_out1)  # Apply ReLU activation\n        \n        # Second BiLSTM layer\n        lstm_out2, _ = self.bilstm2(lstm_out1)\n        lstm_out2 = self.norm2(lstm_out2)  # Apply normalization\n        lstm_out2 = F.relu(lstm_out2)  # Apply ReLU activation\n        \n        # Get the last time step output from the sequence\n        x = lstm_out2[:, -1, :]  # Shape (batch_size, hidden_size * 2)\n        \n        # Fully connected layers\n        x = F.relu(self.fc1(x))  # First fully connected layer\n        x = F.relu(self.fc2(x))  # Second fully connected layer\n        \n        return x\n\n\nclass SpatioTemporalAttention(nn.Module):\n    def __init__(self, spatial_feature_size, temporal_feature_size):\n        super(SpatioTemporalAttention, self).__init__()\n        \n        self.concat_size = spatial_feature_size + temporal_feature_size   # Size of concatenated features\n\n        # Fully connected layers for feature compression and transformation\n        self.fc1 = nn.Linear(self.concat_size, self.concat_size)\n        self.fc2 = nn.Linear(self.concat_size, self.concat_size // 8)\n        self.fc3 = nn.Linear(self.concat_size // 8, self.concat_size)\n\n        # Fully connected layer for attention weights\n        self.fc4 = nn.Linear(self.concat_size, self.concat_size)\n    \n    def forward(self, spatial_feat, temporal_feat):\n        # Concatenate spatial and temporal features\n        combined_feat = torch.cat((spatial_feat, temporal_feat), dim=1)  # Shape: (batch_size, concat_size)\n\n        # Apply compression layers with ReLU activation\n        x = F.relu(self.fc1(combined_feat))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n\n        # Compute attention weights using sigmoid activation\n        attention_weights = torch.sigmoid(self.fc4(x))  # Shape: (batch_size, concat_size)\n\n        # Element-wise multiplication to fuse features with attention weights\n        fused_features = combined_feat * attention_weights  # Shape: (batch_size, concat_size)\n\n        return fused_features\n\n\nclass ClassificationNetwork(nn.Module):\n    def __init__(self, input_size):\n        super(ClassificationNetwork, self).__init__()\n        \n        # Define fully connected layers\n        self.fc1 = nn.Linear(input_size, 400)\n        self.fc2 = nn.Linear(400, 256)\n        self.fc3 = nn.Linear(256, 128)\n        self.fc4 = nn.Linear(128, 32)\n        \n        # Define dropout layer\n        self.dropout = nn.Dropout(0.2)\n        \n        # Define final fully connected layer for output\n        self.fc5 = nn.Linear(32, 1)  # Output is binary classification, so 2 neurons\n\n    def forward(self, x):\n        # Pass through the first fully connected layer and apply Leaky ReLU\n        x = F.leaky_relu(self.fc1(x))\n        x = self.dropout(x)\n        \n        # Pass through the second fully connected layer and apply Leaky ReLU\n        x = F.leaky_relu(self.fc2(x))\n        x = self.dropout(x)\n        \n        # Pass through the third fully connected layer and apply Leaky ReLU\n        x = F.leaky_relu(self.fc3(x))\n        x = self.dropout(x)\n        \n        # Pass through the fourth fully connected layer and apply Leaky ReLU\n        x = F.leaky_relu(self.fc4(x))\n        x = self.dropout(x)\n        \n        # Output layer with softmax activation\n        x = self.fc5(x)\n        #x = F.softmax(x, dim=1)  # Use log_softmax for numerical stability\n        \n        return x\n\n# Complete Network\nclass ParallelCNNBiLSTM(nn.Module):\n    def __init__(self, temporal_input_size, spatial_input_size):\n        super(ParallelCNNBiLSTM, self).__init__()\n        self.spatial_extractor = CNNSpatialExtractor(input_size = spatial_input_size)\n        self.temporal_extractor = DeepBiLSTMTemporalExtractor(input_size=temporal_input_size, hidden_size=temporal_input_size)\n        self.attention = SpatioTemporalAttention(256, 256)\n        self.classifier = ClassificationNetwork(input_size=2 * 256)\n\n    def forward(self, spatial_input, temporal_input):\n        spatial_features = self.spatial_extractor(spatial_input)\n        temporal_features = self.temporal_extractor(temporal_input)\n        fused_features = self.attention(spatial_features, temporal_features)\n        output = self.classifier(fused_features)\n        return output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=10, min_delta=0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n\n    def __call__(self, val_loss):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n        elif val_loss > self.best_loss - self.min_delta:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_loss = val_loss\n            self.counter = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spatial_input_size = 46  # Height and width for CNN input\ntemporal_input_size = 25  # Input size for LSTM\nsequence_length = 85  # Temporal sequence length\n\n# Create model\nmodel = ParallelCNNBiLSTM(temporal_input_size=temporal_input_size, spatial_input_size=spatial_input_size).to(device)\n\n# Print summary using torchinfo\nfrom torchinfo import summary\nsummary(model, input_size=[(BATCH_SIZE, 1, spatial_input_size, spatial_input_size), (BATCH_SIZE, sequence_length, temporal_input_size)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###...............................Load the data...............................###\ndata_spatial_synth = np.load(DATA_DIR_SYNTH_FREQS_10s / \"synthetic_spatial_freqs.npy\", allow_pickle=True)\ndata_temporal_synth = np.load(DATA_DIR_SYNTH_FREQS_10s / \"synthetic_temporal_freqs.npy\", allow_pickle=True)\nlabels_synth = np.load(DATA_DIR_SYNTH_FREQS_10s / \"synthetic_labels_freqs.npy\", allow_pickle=True)\n\ndata_spatial_whuref = np.load(DATA_DIR_WHUREF_FREQS_10s / \"whu_ref_spatial_freqs.npy\", allow_pickle=True)\ndata_temporal_whuref = np.load(DATA_DIR_WHUREF_FREQS_10s / \"whu_ref_temporal_freqs.npy\", allow_pickle=True)\nlabels_whuref = np.load(DATA_DIR_WHUREF_FREQS_10s / \"whu_ref_labels_freqs.npy\", allow_pickle=True)\n\ndata_spatial_carioca = np.load(DATA_DIR_CARIOCA_FREQS_10s / \"carioca_spatial_freqs.npy\", allow_pickle=True)\ndata_temporal_carioca = np.load(DATA_DIR_CARIOCA_FREQS_10s / \"carioca_temporal_freqs.npy\", allow_pickle=True)\nlabels_carioca = np.load(DATA_DIR_CARIOCA_FREQS_10s / \"carioca_labels_freqs.npy\", allow_pickle=True)\n\n\n\n###...............................Normalize...............................###\n\n## Spatial Data Synthetic\ndata_spatial_reshaped_synth = data_spatial_synth.reshape(data_spatial_synth.shape[0], -1) # Reshape data for RobustScaler (n_samples, n_features) format\nscaler_spatial = RobustScaler() # Apply RobustScaler\ndata_spatial_normalized_synth = scaler_spatial.fit_transform(data_spatial_reshaped_synth)\ndata_spatial_normalized_synth = data_spatial_normalized_synth.reshape(data_spatial_synth.shape) # Reshape back to original shape\ndata_spatial_tensor_synth = torch.tensor(data_spatial_normalized_synth, dtype=torch.float32) # Convert to tensors\n\n## Temporal Data Synthetic\ndata_temporal_reshaped_synth = data_temporal_synth.reshape(data_temporal_synth.shape[0], -1) # Reshape data for RobustScaler (n_samples, n_features) format\nscaler_temporal = RobustScaler() # Apply RobustScaler\ndata_temporal_normalized_synth = scaler_temporal.fit_transform(data_temporal_reshaped_synth)\ndata_temporal_normalized_synth = data_temporal_normalized_synth.reshape(data_temporal_synth.shape) # Reshape back to original shape\ndata_temporal_tensor_synth = torch.tensor(data_temporal_normalized_synth, dtype=torch.float32) # Convert to tensors\n\n\n## Spatial Data Whuref\ndata_spatial_reshaped_whuref = data_spatial_whuref.reshape(data_spatial_whuref.shape[0], -1) # Reshape data for RobustScaler (n_samples, n_features) format\nscaler_spatial = RobustScaler() # Apply RobustScaler\ndata_spatial_normalized_whuref = scaler_spatial.fit_transform(data_spatial_reshaped_whuref)\ndata_spatial_normalized_whuref = data_spatial_normalized_whuref.reshape(data_spatial_whuref.shape) # Reshape back to original shape\ndata_spatial_tensor_whuref = torch.tensor(data_spatial_normalized_whuref, dtype=torch.float32) # Convert to tensors\n\n## Temporal Data Whuref\ndata_temporal_reshaped_whuref = data_temporal_whuref.reshape(data_temporal_whuref.shape[0], -1) # Reshape data for RobustScaler (n_samples, n_features) format\nscaler_temporal = RobustScaler() # Apply RobustScaler\ndata_temporal_normalized_whuref = scaler_temporal.fit_transform(data_temporal_reshaped_whuref)\ndata_temporal_normalized_whuref = data_temporal_normalized_whuref.reshape(data_temporal_whuref.shape) # Reshape back to original shape\ndata_temporal_tensor_whuref = torch.tensor(data_temporal_normalized_whuref, dtype=torch.float32) # Convert to tensors\n\n\n## Spatial Data Carioca\ndata_spatial_reshaped_carioca = data_spatial_carioca.reshape(data_spatial_carioca.shape[0], -1) # Reshape data for RobustScaler (n_samples, n_features) format\nscaler_spatial = RobustScaler() # Apply RobustScaler\ndata_spatial_normalized_carioca = scaler_spatial.fit_transform(data_spatial_reshaped_carioca)\ndata_spatial_normalized_carioca = data_spatial_normalized_carioca.reshape(data_spatial_carioca.shape) # Reshape back to original shape\ndata_spatial_tensor_carioca = torch.tensor(data_spatial_normalized_carioca, dtype=torch.float32) # Convert to tensors\n\n## Temporal Data Carioca\ndata_temporal_reshaped_carioca = data_temporal_carioca.reshape(data_temporal_carioca.shape[0], -1) # Reshape data for RobustScaler (n_samples, n_features) format\nscaler_temporal = RobustScaler() # Apply RobustScaler\ndata_temporal_normalized_carioca = scaler_temporal.fit_transform(data_temporal_reshaped_carioca)\ndata_temporal_normalized_carioca = data_temporal_normalized_carioca.reshape(data_temporal_carioca.shape) # Reshape back to original shape\ndata_temporal_tensor_carioca = torch.tensor(data_temporal_normalized_carioca, dtype=torch.float32) # Convert to tensors\n\n\n\n\n###...............................Split into Training Validation and Test data...............................###\n\n## Synthetic\nX_spatial_train_synth, X_spatial_test_synth, X_temporal_train_synth, X_temporal_test_synth, y_train_synth, y_test_synth = (\n    train_test_split(\n        data_spatial_tensor_synth,\n        data_temporal_tensor_synth,\n        labels_synth,\n        test_size=TEST_SIZE,\n        random_state=0,\n        stratify=labels_synth,\n    )\n)\n\nX_spatial_train_synth, X_spatial_val_synth, X_temporal_train_synth, X_temporal_val_synth, y_train_synth, y_val_synth = (\n    train_test_split(\n        X_spatial_train_synth,\n        X_temporal_train_synth,\n        y_train_synth,\n        test_size=TEST_SIZE,\n        random_state=0,\n        stratify=y_train_synth,\n    )\n)\n\n## Whuref\nX_spatial_train_whuref, X_spatial_test_whuref, X_temporal_train_whuref, X_temporal_test_whuref, y_train_whuref, y_test_whuref = (\n    train_test_split(\n        data_spatial_tensor_whuref,\n        data_temporal_tensor_whuref,\n        labels_whuref,\n        test_size=TEST_SIZE,\n        random_state=0,\n        stratify=labels_whuref,\n    )\n)\n\nX_spatial_train_whuref, X_spatial_val_whuref, X_temporal_train_whuref, X_temporal_val_whuref, y_train_whuref, y_val_whuref = (\n    train_test_split(\n        X_spatial_train_whuref,\n        X_temporal_train_whuref,\n        y_train_whuref,\n        test_size=TEST_SIZE,\n        random_state=0,\n        stratify=y_train_whuref,\n    )\n)\n\n\n## Carioca\nX_spatial_train_carioca, X_spatial_test_carioca, X_temporal_train_carioca, X_temporal_test_carioca, y_train_carioca, y_test_carioca = (\n    train_test_split(\n        data_spatial_tensor_carioca,\n        data_temporal_tensor_carioca,\n        labels_carioca,\n        test_size=TEST_SIZE,\n        random_state=0,\n        stratify=labels_carioca,\n    )\n)\n\nX_spatial_train_carioca, X_spatial_val_carioca, X_temporal_train_carioca, X_temporal_val_carioca, y_train_carioca, y_val_carioca = (\n    train_test_split(\n        X_spatial_train_carioca,\n        X_temporal_train_carioca,\n        y_train_carioca,\n        test_size=TEST_SIZE,\n        random_state=0,\n        stratify=y_train_carioca,\n    )\n)\n\n## Combine Training Data\nX_spatial_train = torch.cat((X_spatial_train_synth, X_spatial_train_whuref, X_spatial_train_carioca), dim=0)\nX_temporal_train = torch.cat((X_temporal_train_synth, X_temporal_train_whuref,X_temporal_train_carioca), dim=0)\ny_train = np.concatenate((y_train_synth, y_train_whuref, y_train_carioca), axis=0)\n\n## Combine Validation Data\nX_spatial_val = torch.cat((X_spatial_val_synth, X_spatial_val_whuref, X_spatial_val_carioca), dim=0)\nX_temporal_val = torch.cat((X_temporal_val_synth, X_temporal_val_whuref, X_temporal_val_carioca), dim=0)\ny_val = np.concatenate((y_val_synth, y_val_whuref, y_val_carioca), axis=0)\n\n## Combine Validation Data\nX_spatial_test = torch.cat((X_spatial_test_synth, X_spatial_test_whuref, X_spatial_test_carioca), dim=0)\nX_temporal_test = torch.cat((X_temporal_test_synth, X_temporal_test_whuref, X_temporal_test_carioca), dim=0)\ny_test = np.concatenate((y_test_synth, y_test_whuref, y_test_carioca), axis=0)\n\n\n\n###..................................Convert Data Tensors and move to the GPU..................................###\n# Convert spatial data tensors and move to device\nX_spatial_train = X_spatial_train.unsqueeze(1).to(device)\nX_spatial_val = X_spatial_val.unsqueeze(1).to(device)\nX_spatial_test = X_spatial_test.unsqueeze(1).to(device)\nX_spatial_test_synth = X_spatial_test_synth.unsqueeze(1).to(device)\nX_spatial_test_whuref = X_spatial_test_whuref.unsqueeze(1).to(device)\nX_spatial_test_carioca = X_spatial_test_carioca.unsqueeze(1).to(device)\n\n# Convert temporal data tensors and move to device\nX_temporal_train = X_temporal_train.to(device)\nX_temporal_val = X_temporal_val.to(device)\nX_temporal_test = X_temporal_test.to(device)\nX_temporal_test_synth = X_temporal_test_synth.to(device)\nX_temporal_test_whuref = X_temporal_test_whuref.to(device)\nX_temporal_test_carioca = X_temporal_test_carioca.to(device)\n\n# Convert labels to tensors and move to device\ny_train = torch.LongTensor(y_train).to(device)\ny_val = torch.LongTensor(y_val).to(device)\ny_test = torch.LongTensor(y_test).to(device)\ny_test_synth = torch.LongTensor(y_test_synth).to(device)\ny_test_whuref = torch.LongTensor(y_test_whuref).to(device)\ny_test_carioca = torch.LongTensor(y_test_carioca).to(device)\n\n\n\n###.....................Create TensorDatasets for spatial and temporal inputs.....................###\ntrain_dataset = TensorDataset(X_spatial_train, X_temporal_train, y_train)\nval_dataset = TensorDataset(X_spatial_val, X_temporal_val, y_val)\ntest_dataset = TensorDataset(X_spatial_test, X_temporal_test, y_test)\ntest_dataset_synth = TensorDataset(X_spatial_test_synth, X_temporal_test_synth, y_test_synth)\ntest_dataset_whuref = TensorDataset(X_spatial_test_whuref, X_temporal_test_whuref, y_test_whuref)\ntest_dataset_carioca = TensorDataset(X_spatial_test_carioca, X_temporal_test_carioca, y_test_carioca)\n\n# Data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader_synth = DataLoader(test_dataset_synth, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader_whuref = DataLoader(test_dataset_whuref, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader_carioca = DataLoader(test_dataset_carioca, batch_size=BATCH_SIZE, shuffle=False)\n\n\n\n###.........................Check label distribution for training.........................###\nunique, counts = np.unique(y_train.cpu(), return_counts=True)\nclass_distribution = dict(zip(unique, counts))\nprint(f\"y_train distribution: {class_distribution}\")\n\nunique, counts = np.unique(y_val.cpu(), return_counts=True)\nclass_distribution = dict(zip(unique, counts))\nprint(f\"y_val distribution: {class_distribution}\")\n\nunique, counts = np.unique(y_test.cpu(), return_counts=True)\nclass_distribution = dict(zip(unique, counts))\nprint(f\"y_test distribution: {class_distribution}\")\n\nunique, counts = np.unique(y_test_synth.cpu(), return_counts=True)\nclass_distribution = dict(zip(unique, counts))\nprint(f\"y_test_synth distribution: {class_distribution}\")\n\nunique, counts = np.unique(y_test_whuref.cpu(), return_counts=True)\nclass_distribution = dict(zip(unique, counts))\nprint(f\"y_test_whuref distribution: {class_distribution}\")\n\nunique, counts = np.unique(y_test_carioca.cpu(), return_counts=True)\nclass_distribution = dict(zip(unique, counts))\nprint(f\"y_test_ distribution: {class_distribution}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss for binary classification\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  # Adam optimizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize EarlyStopping object\n#early_stopping = EarlyStopping(patience=100, min_delta=0.01)\n\n# Training and validation loop\ntrain_losses = []\nval_losses = []\ntrain_accuracies = []\nval_accuracies = []\n\nfor epoch in tqdm(range(NUM_EPOCHS), desc=\"Training Progress\"):\n    # Training\n    model.train()\n    train_loss = 0.0\n    correct_train = 0\n    total_train = 0\n    for spatial_inputs, temporal_inputs, labels in train_loader:  # Assuming data loader returns spatial and temporal inputs\n        optimizer.zero_grad()\n        outputs = model(spatial_inputs, temporal_inputs)\n        \n        # Ensure labels have the same shape as outputs\n        labels = labels.unsqueeze(1).float()  # Convert [64] to [64, 1]\n\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n\n        # Use sigmoid to get predictions for binary classification\n        predictions = torch.sigmoid(outputs)\n        predicted_labels = (predictions > 0.5).float()  # Convert to binary predictions\n        \n        total_train += labels.size(0)\n        correct_train += (predicted_labels == labels).sum().item()\n\n    train_loss /= len(train_loader)\n    train_losses.append(train_loss)\n    train_accuracy = correct_train / total_train\n    train_accuracies.append(train_accuracy)\n\n    # Validation\n    model.eval()\n    val_loss = 0.0\n    correct_val = 0\n    total_val = 0\n    with torch.no_grad():\n        for spatial_inputs, temporal_inputs, labels in val_loader:  # Assuming data loader returns spatial and temporal inputs\n            outputs = model(spatial_inputs, temporal_inputs)\n            \n            # Ensure labels have the same shape as outputs\n            labels = labels.unsqueeze(1).float()  # Convert [64] to [64, 1]\n\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n            # Use sigmoid to get predictions for binary classification\n            predictions = torch.sigmoid(outputs)\n            predicted_labels = (predictions > 0.5).float()  # Convert to binary predictions\n\n            total_val += labels.size(0)\n            correct_val += (predicted_labels == labels).sum().item()\n\n    val_loss /= len(val_loader)\n    val_losses.append(val_loss)\n    val_accuracy = correct_val / total_val\n    val_accuracies.append(val_accuracy)\n\n    tqdm.write(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n    \n    '''\n    # Check early stopping condition\n    early_stopping(val_loss)\n    if early_stopping.early_stop:\n        print(\"Early stopping\")\n        break'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spatial_input_size = 46  # Height and width for CNN input\ntemporal_input_size = 25  # Input size for LSTM\nsequence_length = 85  # Temporal sequence length\n\n# Define the Model\nmodel = ParallelCNNBiLSTM(temporal_input_size=temporal_input_size, spatial_input_size=spatial_input_size).to(device)\n\n# Load the saved model weights\nmodel.load_state_dict(torch.load('//kaggle/input/all-freqs-10s-cnn-bilstm/pytorch/default/1/All_freqs_10s_cnn-bilstm.pth', weights_only=True))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T13:11:24.131936Z","iopub.execute_input":"2024-09-28T13:11:24.132913Z","iopub.status.idle":"2024-09-28T13:11:24.201956Z","shell.execute_reply.started":"2024-09-28T13:11:24.132861Z","shell.execute_reply":"2024-09-28T13:11:24.201035Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"## Alle Daten\n\n# Testing phase\nmodel.eval()\ntest_loss = 0.0\ncorrect = 0\ntotal = 0\ntrue_positive = 0\nfalse_positive = 0\nfalse_negative = 0\ntrue_negative = 0  # For untampered sample recall\n\n# Confusion matrix elements\nconfusion_matrix = torch.zeros(2, 2)  # 2x2 for binary classification\n\nwith torch.no_grad():\n    for spatial_inputs, temporal_inputs, labels in test_loader:  # Assuming data loader returns spatial and temporal inputs\n        outputs = model(spatial_inputs, temporal_inputs)\n        \n        labels = labels.unsqueeze(1).float()  # Adjust labels to match the output dimension\n        \n        loss = criterion(outputs, labels)\n        test_loss += loss.item()\n        \n        predictions = torch.sigmoid(outputs)\n        predicted_labels = (predictions > 0.5).float()  # Convert to binary labels\n        \n        total += labels.size(0)\n        correct += (predicted_labels == labels).sum().item()\n        \n        # Update confusion matrix\n        for t, p in zip(labels.view(-1), predicted_labels.view(-1)):  # Iterate over true and predicted labels\n            confusion_matrix[int(t.long()), int(p.long())] += 1  # Fill confusion matrix\n        \n        # Calculate True Positives, False Positives, False Negatives, and True Negatives\n        true_positive += ((predicted_labels == 1) & (labels == 1)).sum().item()\n        false_positive += ((predicted_labels == 1) & (labels == 0)).sum().item()\n        false_negative += ((predicted_labels == 0) & (labels == 1)).sum().item()\n        true_negative += ((predicted_labels == 0) & (labels == 0)).sum().item()\n\ntest_loss /= len(test_loader)\ntest_accuracy = correct / total\n\n# Calculate Precision\nif true_positive + false_positive > 0:\n    precision = true_positive / (true_positive + false_positive)\nelse:\n    precision = 0.0  # Avoid division by zero\n\n# Calculate Recall for tampered samples (positive class)\nif true_positive + false_negative > 0:\n    recall_tampered = true_positive / (true_positive + false_negative)\nelse:\n    recall_tampered = 0.0  # Avoid division by zero\n\n# Calculate Recall for untampered samples (negative class)\nif true_negative + false_positive > 0:\n    recall_untampered = true_negative / (true_negative + false_positive)\nelse:\n    recall_untampered = 0.0  # Avoid division by zero\n\n# Print results\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Precision: {precision:.4f}, Test Recall (tampered): {recall_tampered:.4f}, Test Recall (untampered): {recall_untampered:.4f}\")\n\n\n# Convert confusion matrix to numpy for plotting\ncm = confusion_matrix.numpy()\n\n# Plotting the confusion matrix using seaborn\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, fmt='.0f', cmap='Blues', xticklabels=['Ungeschnitten', 'Geschnitten'], yticklabels=['Ungeschnitten', 'Geschnitten'])\nplt.xlabel('Vorhergesagtes Label')\nplt.ylabel('Wahres Label')\nplt.title('Confusion Matrix')\nplt.savefig('all_confusion_matrix_cnn-bilstm_all_freqs.pdf', dpi=300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T13:11:56.614414Z","iopub.execute_input":"2024-09-28T13:11:56.615302Z","iopub.status.idle":"2024-09-28T13:11:57.650796Z","shell.execute_reply.started":"2024-09-28T13:11:56.615259Z","shell.execute_reply":"2024-09-28T13:11:57.649861Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Test Loss: 0.2361, Test Accuracy: 0.9441, Test Precision: 0.9133, Test Recall (tampered): 0.9814, Test Recall (untampered): 0.9068\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"## Synthetische Daten\n\n# Testing phase\nmodel.eval()\ntest_loss = 0.0\ncorrect = 0\ntotal = 0\ntrue_positive = 0\nfalse_positive = 0\nfalse_negative = 0\ntrue_negative = 0  # For untampered sample recall\n\n# Confusion matrix elements\nconfusion_matrix = torch.zeros(2, 2)  # 2x2 for binary classification\n\nwith torch.no_grad():\n    for spatial_inputs, temporal_inputs, labels in test_loader_synth:  # Assuming data loader returns spatial and temporal inputs\n        outputs = model(spatial_inputs, temporal_inputs)\n        \n        labels = labels.unsqueeze(1).float()  # Adjust labels to match the output dimension\n        \n        loss = criterion(outputs, labels)\n        test_loss += loss.item()\n        \n        predictions = torch.sigmoid(outputs)\n        predicted_labels = (predictions > 0.5).float()  # Convert to binary labels\n        \n        total += labels.size(0)\n        correct += (predicted_labels == labels).sum().item()\n        \n        # Update confusion matrix\n        for t, p in zip(labels.view(-1), predicted_labels.view(-1)):  # Iterate over true and predicted labels\n            confusion_matrix[int(t.long()), int(p.long())] += 1  # Fill confusion matrix\n        \n        # Calculate True Positives, False Positives, False Negatives, and True Negatives\n        true_positive += ((predicted_labels == 1) & (labels == 1)).sum().item()\n        false_positive += ((predicted_labels == 1) & (labels == 0)).sum().item()\n        false_negative += ((predicted_labels == 0) & (labels == 1)).sum().item()\n        true_negative += ((predicted_labels == 0) & (labels == 0)).sum().item()\n\ntest_loss /= len(test_loader_synth)\ntest_accuracy = correct / total\n\n# Calculate Precision\nif true_positive + false_positive > 0:\n    precision = true_positive / (true_positive + false_positive)\nelse:\n    precision = 0.0  # Avoid division by zero\n\n# Calculate Recall for tampered samples (positive class)\nif true_positive + false_negative > 0:\n    recall_tampered = true_positive / (true_positive + false_negative)\nelse:\n    recall_tampered = 0.0  # Avoid division by zero\n\n# Calculate Recall for untampered samples (negative class)\nif true_negative + false_positive > 0:\n    recall_untampered = true_negative / (true_negative + false_positive)\nelse:\n    recall_untampered = 0.0  # Avoid division by zero\n\n# Print results\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Precision: {precision:.4f}, Test Recall (tampered): {recall_tampered:.4f}, Test Recall (untampered): {recall_untampered:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training and validation losses and accuracies\nplt.figure(figsize=(12, 6))\n\n# Plotting Training and Validation Loss\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label=\"Train Loss\", alpha=0.7)\nplt.plot(val_losses, label=\"Validation Loss\", alpha=0.7)\nplt.xlabel(\"Epoche\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.title(\"Training and Validation Loss\")\n\n# Plotting Training and Validation Accuracy\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracies, label=\"Train Accuracy\", alpha=0.7)\nplt.plot(val_accuracies, label=\"Validation Accuracy\", alpha=0.7)\nplt.xlabel(\"Epoche\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title(\"Training und Validation Accuracy\")\nplt.savefig('Valdidation_accuracy_and_loss_cnn-bilstm_all_freqs.pdf', dpi=300)\nplt.tight_layout()\nplt.show()\n\n\n# Convert confusion matrix to numpy for plotting\ncm = confusion_matrix.numpy()\n\n# Plotting the confusion matrix using seaborn\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, fmt='.0f', cmap='Blues', xticklabels=['Ungeschnitten', 'Geschnitten'], yticklabels=['Ungeschnitten', 'Geschnitten'])\nplt.xlabel('Vorhergesagtes Label')\nplt.ylabel('Wahres Label')\nplt.title('Confusion Matrix')\nplt.savefig('synth_confusion_matrix_cnn-bilstm_all_freqs.pdf', dpi=300)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## WHU Ref Data\n\n# Testing phase\nmodel.eval()\ntest_loss = 0.0\ncorrect = 0\ntotal = 0\ntrue_positive = 0\nfalse_positive = 0\nfalse_negative = 0\ntrue_negative = 0  # For untampered sample recall\n\n# Confusion matrix elements\nconfusion_matrix = torch.zeros(2, 2)  # 2x2 for binary classification\n\nwith torch.no_grad():\n    for spatial_inputs, temporal_inputs, labels in test_loader_whuref:  # Assuming data loader returns spatial and temporal inputs\n        outputs = model(spatial_inputs, temporal_inputs)\n        \n        labels = labels.unsqueeze(1).float()  # Adjust labels to match the output dimension\n        \n        loss = criterion(outputs, labels)\n        test_loss += loss.item()\n        \n        predictions = torch.sigmoid(outputs)\n        predicted_labels = (predictions > 0.5).float()  # Convert to binary labels\n        \n        total += labels.size(0)\n        correct += (predicted_labels == labels).sum().item()\n        \n        # Update confusion matrix\n        for t, p in zip(labels.view(-1), predicted_labels.view(-1)):  # Iterate over true and predicted labels\n            confusion_matrix[int(t.long()), int(p.long())] += 1  # Fill confusion matrix\n        \n        # Calculate True Positives, False Positives, False Negatives, and True Negatives\n        true_positive += ((predicted_labels == 1) & (labels == 1)).sum().item()\n        false_positive += ((predicted_labels == 1) & (labels == 0)).sum().item()\n        false_negative += ((predicted_labels == 0) & (labels == 1)).sum().item()\n        true_negative += ((predicted_labels == 0) & (labels == 0)).sum().item()\n\ntest_loss /= len(test_loader_whuref)\ntest_accuracy = correct / total\n\n# Calculate Precision\nif true_positive + false_positive > 0:\n    precision = true_positive / (true_positive + false_positive)\nelse:\n    precision = 0.0  # Avoid division by zero\n\n# Calculate Recall for tampered samples (positive class)\nif true_positive + false_negative > 0:\n    recall_tampered = true_positive / (true_positive + false_negative)\nelse:\n    recall_tampered = 0.0  # Avoid division by zero\n\n# Calculate Recall for untampered samples (negative class)\nif true_negative + false_positive > 0:\n    recall_untampered = true_negative / (true_negative + false_positive)\nelse:\n    recall_untampered = 0.0  # Avoid division by zero\n\n# Print results\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Precision: {precision:.4f}, Test Recall (tampered): {recall_tampered:.4f}, Test Recall (untampered): {recall_untampered:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert confusion matrix to numpy for plotting\ncm = confusion_matrix.numpy()\n\n# Plotting the confusion matrix using seaborn\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, fmt='.0f', cmap='Blues', xticklabels=['Ungeschnitten', 'Geschnitten'], yticklabels=['Ungeschnitten', 'Geschnitten'])\nplt.xlabel('Vorhergesagtes Label')\nplt.ylabel('Wahres Label')\nplt.title('Confusion Matrix')\nplt.savefig('whuref_confusion_matrix_cnn-bilstm_all_freqs.pdf', dpi=300)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Carioca Data\n\n# Testing phase\nmodel.eval()\ntest_loss = 0.0\ncorrect = 0\ntotal = 0\ntrue_positive = 0\nfalse_positive = 0\nfalse_negative = 0\ntrue_negative = 0  # For untampered sample recall\n\n# Confusion matrix elements\nconfusion_matrix = torch.zeros(2, 2)  # 2x2 for binary classification\n\nwith torch.no_grad():\n    for spatial_inputs, temporal_inputs, labels in test_loader_carioca:  # Assuming data loader returns spatial and temporal inputs\n        outputs = model(spatial_inputs, temporal_inputs)\n        \n        labels = labels.unsqueeze(1).float()  # Adjust labels to match the output dimension\n        \n        loss = criterion(outputs, labels)\n        test_loss += loss.item()\n        \n        predictions = torch.sigmoid(outputs)\n        predicted_labels = (predictions > 0.5).float()  # Convert to binary labels\n        \n        total += labels.size(0)\n        correct += (predicted_labels == labels).sum().item()\n        \n        # Update confusion matrix\n        for t, p in zip(labels.view(-1), predicted_labels.view(-1)):  # Iterate over true and predicted labels\n            confusion_matrix[int(t.long()), int(p.long())] += 1  # Fill confusion matrix\n        \n        # Calculate True Positives, False Positives, False Negatives, and True Negatives\n        true_positive += ((predicted_labels == 1) & (labels == 1)).sum().item()\n        false_positive += ((predicted_labels == 1) & (labels == 0)).sum().item()\n        false_negative += ((predicted_labels == 0) & (labels == 1)).sum().item()\n        true_negative += ((predicted_labels == 0) & (labels == 0)).sum().item()\n\ntest_loss /= len(test_loader_carioca)\ntest_accuracy = correct / total\n\n# Calculate Precision\nif true_positive + false_positive > 0:\n    precision = true_positive / (true_positive + false_positive)\nelse:\n    precision = 0.0  # Avoid division by zero\n\n# Calculate Recall for tampered samples (positive class)\nif true_positive + false_negative > 0:\n    recall_tampered = true_positive / (true_positive + false_negative)\nelse:\n    recall_tampered = 0.0  # Avoid division by zero\n\n# Calculate Recall for untampered samples (negative class)\nif true_negative + false_positive > 0:\n    recall_untampered = true_negative / (true_negative + false_positive)\nelse:\n    recall_untampered = 0.0  # Avoid division by zero\n\n# Print results\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Precision: {precision:.4f}, Test Recall (tampered): {recall_tampered:.4f}, Test Recall (untampered): {recall_untampered:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Plot Carioca confusion matrix\n# Convert confusion matrix to numpy for plotting\ncm = confusion_matrix.numpy()\n\n# Plotting the confusion matrix using seaborn\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, fmt='.0f', cmap='Blues', xticklabels=['Ungeschnitten', 'Geschnitten'], yticklabels=['Ungeschnitten', 'Geschnitten'])\nplt.xlabel('Vorhergesagtes Label')\nplt.ylabel('Wahres Label')\nplt.title('Confusion Matrix')\nplt.savefig('carioca_confusion_matrix_cnn-bilstm_all_freqs.pdf', dpi=300)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model\ntorch.save(model.state_dict(), \"All_freqs_10s_cnn-bilstm.pth\")\nprint(\"Model saved successfully!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}