{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9428816,"sourceType":"datasetVersion","datasetId":5728003},{"sourceId":9480074,"sourceType":"datasetVersion","datasetId":5766277},{"sourceId":9480083,"sourceType":"datasetVersion","datasetId":5766284},{"sourceId":9480097,"sourceType":"datasetVersion","datasetId":5766297},{"sourceId":9485179,"sourceType":"datasetVersion","datasetId":5770118},{"sourceId":9485921,"sourceType":"datasetVersion","datasetId":5770698},{"sourceId":9487402,"sourceType":"datasetVersion","datasetId":5771806},{"sourceId":9487465,"sourceType":"datasetVersion","datasetId":5771853},{"sourceId":9489223,"sourceType":"datasetVersion","datasetId":5773160},{"sourceId":9504453,"sourceType":"datasetVersion","datasetId":5784691}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pickle\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom torch.utils.data import DataLoader, SubsetRandomSampler, TensorDataset\nfrom tqdm.notebook import tqdm\nimport sklearn\nprint(sklearn.__version__)\n\n# Ensure reproducibility\nSEED = 0\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\n\n# Define data directory based on environment\nDATA_DIR_CARIOCA_FREQS_10s = Path(\"/kaggle/input/carioca-freqs-10s-cnn-bilstm\")\nDATA_DIR_SYNTH_FREQS_10s = Path(\"/kaggle/input/synthetic-variety-freqs-10s-cnn-bilstm\")\nDATA_DIR_WHUREF_FREQS_10s = Path(\"/kaggle/input/whuref-freqs-10s-cnn-bilstm\")","metadata":{"execution":{"iopub.status.busy":"2024-09-29T15:29:49.447316Z","iopub.execute_input":"2024-09-29T15:29:49.447747Z","iopub.status.idle":"2024-09-29T15:29:49.457599Z","shell.execute_reply.started":"2024-09-29T15:29:49.447708Z","shell.execute_reply":"2024-09-29T15:29:49.456434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use CUDA if a GPU is available\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\nprint(\"Using device\", device)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T15:29:49.48123Z","iopub.execute_input":"2024-09-29T15:29:49.48164Z","iopub.status.idle":"2024-09-29T15:29:49.487643Z","shell.execute_reply.started":"2024-09-29T15:29:49.481603Z","shell.execute_reply":"2024-09-29T15:29:49.486617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nNUM_EPOCHS = 200\nBATCH_SIZE = 64\nLEARNING_RATE = 0.00001\nTEST_SIZE = 0.2\n\nNAME = \"cnn_bilstm_alldata\"","metadata":{"execution":{"iopub.status.busy":"2024-09-29T15:29:49.496475Z","iopub.execute_input":"2024-09-29T15:29:49.496822Z","iopub.status.idle":"2024-09-29T15:29:49.501477Z","shell.execute_reply.started":"2024-09-29T15:29:49.49679Z","shell.execute_reply":"2024-09-29T15:29:49.500473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNNSpatialExtractor(nn.Module):\n    def __init__(self, input_size):\n        super(CNNSpatialExtractor, self).__init__()\n        # Convolution layers with padding to preserve spatial dimensions\n        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        final_size = input_size // 8\n        \n        # Compute the flattened size after convolutions and pooling\n        self.fc1 = nn.Linear(64 * final_size * final_size, 1024)  # Flattened size: 64 channels * 5x5\n        self.fc2 = nn.Linear(1024, 256)         # Second fully connected layer\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))  # Output size: (22x22)\n        x = self.pool(F.relu(self.conv2(x)))  # Output size: (11x11)\n        x = self.pool(F.relu(self.conv3(x)))  # Output size: (5x5)\n        x = x.view(x.size(0), -1)  # Flatten the output\n        x = F.relu(self.fc1(x))   # First fully connected layer\n        x = F.relu(self.fc2(x))   # Second fully connected layer\n        return x\n\n\n# BiLSTM block for temporal feature extraction\nclass DeepBiLSTMTemporalExtractor(nn.Module):\n    def __init__(self, input_size=85, hidden_size=85, num_layers=2):\n        super(DeepBiLSTMTemporalExtractor, self).__init__()\n        \n        # First BiLSTM module\n        self.bilstm1 = nn.LSTM(input_size, hidden_size, num_layers=1, bidirectional=True, batch_first=True)\n        self.norm1 = nn.LayerNorm(hidden_size * 2)  # Normalization layer for the first BiLSTM\n        \n        # Second BiLSTM module\n        self.bilstm2 = nn.LSTM(hidden_size * 2, hidden_size, num_layers=1, bidirectional=True, batch_first=True)\n        self.norm2 = nn.LayerNorm(hidden_size * 2)  # Normalization layer for the second BiLSTM\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(hidden_size * 2, 512)  # First fully connected layer (input: hidden_size*2, output: 512)\n        self.fc2 = nn.Linear(512, 256)  # Second fully connected layer (input: 512, output: 256)\n\n    def forward(self, x):\n        # First BiLSTM layer\n        lstm_out1, _ = self.bilstm1(x)\n        lstm_out1 = self.norm1(lstm_out1)  # Apply normalization\n        lstm_out1 = F.relu(lstm_out1)  # Apply ReLU activation\n        \n        # Second BiLSTM layer\n        lstm_out2, _ = self.bilstm2(lstm_out1)\n        lstm_out2 = self.norm2(lstm_out2)  # Apply normalization\n        lstm_out2 = F.relu(lstm_out2)  # Apply ReLU activation\n        \n        # Get the last time step output from the sequence\n        x = lstm_out2[:, -1, :]  # Shape (batch_size, hidden_size * 2)\n        \n        # Fully connected layers\n        x = F.relu(self.fc1(x))  # First fully connected layer\n        x = F.relu(self.fc2(x))  # Second fully connected layer\n        \n        return x\n\n\nclass SpatioTemporalAttention(nn.Module):\n    def __init__(self, spatial_feature_size, temporal_feature_size):\n        super(SpatioTemporalAttention, self).__init__()\n        \n        self.concat_size = spatial_feature_size + temporal_feature_size   # Size of concatenated features\n\n        # Fully connected layers for feature compression and transformation\n        self.fc1 = nn.Linear(self.concat_size, self.concat_size)\n        self.fc2 = nn.Linear(self.concat_size, self.concat_size // 8)\n        self.fc3 = nn.Linear(self.concat_size // 8, self.concat_size)\n\n        # Fully connected layer for attention weights\n        self.fc4 = nn.Linear(self.concat_size, self.concat_size)\n    \n    def forward(self, spatial_feat, temporal_feat):\n        # Concatenate spatial and temporal features\n        combined_feat = torch.cat((spatial_feat, temporal_feat), dim=1)  # Shape: (batch_size, concat_size)\n\n        # Apply compression layers with ReLU activation\n        x = F.relu(self.fc1(combined_feat))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n\n        # Compute attention weights using sigmoid activation\n        attention_weights = torch.sigmoid(self.fc4(x))  # Shape: (batch_size, concat_size)\n\n        # Element-wise multiplication to fuse features with attention weights\n        fused_features = combined_feat * attention_weights  # Shape: (batch_size, concat_size)\n\n        return fused_features\n\n\nclass ClassificationNetwork(nn.Module):\n    def __init__(self, input_size):\n        super(ClassificationNetwork, self).__init__()\n        \n        # Define fully connected layers\n        self.fc1 = nn.Linear(input_size, 400)\n        self.fc2 = nn.Linear(400, 256)\n        self.fc3 = nn.Linear(256, 128)\n        self.fc4 = nn.Linear(128, 32)\n        \n        # Define dropout layer\n        self.dropout = nn.Dropout(0.2)\n        \n        # Define final fully connected layer for output\n        self.fc5 = nn.Linear(32, 1)  # Output is binary classification, so 2 neurons\n\n    def forward(self, x):\n        # Pass through the first fully connected layer and apply Leaky ReLU\n        x = F.leaky_relu(self.fc1(x))\n        x = self.dropout(x)\n        \n        # Pass through the second fully connected layer and apply Leaky ReLU\n        x = F.leaky_relu(self.fc2(x))\n        x = self.dropout(x)\n        \n        # Pass through the third fully connected layer and apply Leaky ReLU\n        x = F.leaky_relu(self.fc3(x))\n        x = self.dropout(x)\n        \n        # Pass through the fourth fully connected layer and apply Leaky ReLU\n        x = F.leaky_relu(self.fc4(x))\n        x = self.dropout(x)\n        \n        # Output layer with softmax activation\n        x = self.fc5(x)\n        #x = F.softmax(x, dim=1)  # Use log_softmax for numerical stability\n        \n        return x\n\n# Complete Network\nclass ParallelCNNBiLSTM(nn.Module):\n    def __init__(self, temporal_input_size, spatial_input_size):\n        super(ParallelCNNBiLSTM, self).__init__()\n        self.spatial_extractor = CNNSpatialExtractor(input_size = spatial_input_size)\n        self.temporal_extractor = DeepBiLSTMTemporalExtractor(input_size=temporal_input_size, hidden_size=temporal_input_size)\n        self.attention = SpatioTemporalAttention(256, 256)\n        self.classifier = ClassificationNetwork(input_size=2 * 256)\n\n    def forward(self, spatial_input, temporal_input):\n        spatial_features = self.spatial_extractor(spatial_input)\n        temporal_features = self.temporal_extractor(temporal_input)\n        fused_features = self.attention(spatial_features, temporal_features)\n        output = self.classifier(fused_features)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-09-29T15:29:49.522827Z","iopub.execute_input":"2024-09-29T15:29:49.523182Z","iopub.status.idle":"2024-09-29T15:29:49.551597Z","shell.execute_reply.started":"2024-09-29T15:29:49.523149Z","shell.execute_reply":"2024-09-29T15:29:49.550518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class EarlyStopping:\n#     def __init__(self, patience=10, min_delta=0):\n#         self.patience = patience\n#         self.min_delta = min_delta\n#         self.counter = 0\n#         self.best_loss = None\n#         self.early_stop = False\n\n#     def __call__(self, val_loss):\n#         if self.best_loss is None:\n#             self.best_loss = val_loss\n#         elif val_loss > self.best_loss - self.min_delta:\n#             self.counter += 1\n#             if self.counter >= self.patience:\n#                 self.early_stop = True\n#         else:\n#             self.best_loss = val_loss\n#             self.counter = 0","metadata":{"execution":{"iopub.status.busy":"2024-09-29T15:29:49.553217Z","iopub.execute_input":"2024-09-29T15:29:49.553581Z","iopub.status.idle":"2024-09-29T15:29:49.564932Z","shell.execute_reply.started":"2024-09-29T15:29:49.553542Z","shell.execute_reply":"2024-09-29T15:29:49.56396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spatial_input_size = 46  # Height and width for CNN input\ntemporal_input_size = 25  # Input size for LSTM\nsequence_length = 85  # Temporal sequence length\n\n# Create model\nmodel = ParallelCNNBiLSTM(temporal_input_size=temporal_input_size, spatial_input_size=spatial_input_size).to(device)\n\n# Print summary using torchinfo\n# from torchinfo import summary\n# summary(model, input_size=[(BATCH_SIZE, 1, spatial_input_size, spatial_input_size), (BATCH_SIZE, sequence_length, temporal_input_size)])","metadata":{"execution":{"iopub.status.busy":"2024-09-29T15:29:49.566642Z","iopub.execute_input":"2024-09-29T15:29:49.56699Z","iopub.status.idle":"2024-09-29T15:29:49.612985Z","shell.execute_reply.started":"2024-09-29T15:29:49.566955Z","shell.execute_reply":"2024-09-29T15:29:49.611968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###...............................Load the data...............................###\ndata_spatial_synth = np.load(DATA_DIR_SYNTH_FREQS_10s / \"synthetic_spatial_freqs.npy\", allow_pickle=True)\ndata_temporal_synth = np.load(DATA_DIR_SYNTH_FREQS_10s / \"synthetic_temporal_freqs.npy\", allow_pickle=True)\nlabels_synth = np.load(DATA_DIR_SYNTH_FREQS_10s / \"synthetic_labels_freqs.npy\", allow_pickle=True)\n\ndata_spatial_whuref = np.load(DATA_DIR_WHUREF_FREQS_10s / \"whu_ref_spatial_freqs.npy\", allow_pickle=True)\ndata_temporal_whuref = np.load(DATA_DIR_WHUREF_FREQS_10s / \"whu_ref_temporal_freqs.npy\", allow_pickle=True)\nlabels_whuref = np.load(DATA_DIR_WHUREF_FREQS_10s / \"whu_ref_labels_freqs.npy\", allow_pickle=True)\n\ndata_spatial_carioca = np.load(DATA_DIR_CARIOCA_FREQS_10s / \"carioca_spatial_freqs.npy\", allow_pickle=True)\ndata_temporal_carioca = np.load(DATA_DIR_CARIOCA_FREQS_10s / \"carioca_temporal_freqs.npy\", allow_pickle=True)\nlabels_carioca = np.load(DATA_DIR_CARIOCA_FREQS_10s / \"carioca_labels_freqs.npy\", allow_pickle=True)\n\n\n# Concatenate\ndata_spatial = np.concatenate((data_spatial_synth, data_spatial_whuref, data_spatial_carioca), axis=0)\ndata_temporal = np.concatenate((data_temporal_synth, data_temporal_whuref, data_temporal_carioca), axis=0)\nlabels = np.concatenate((labels_synth, labels_whuref, labels_carioca), axis=0)\ndset = np.concatenate((np.zeros(len(labels_synth)), np.ones(len(labels_whuref)), np.ones(len(labels_carioca)) * 2))\nstratify = np.stack((labels, dset), axis=-1)\n\n\n###...............................Normalize...............................###\nscaler_spatial = RobustScaler() # Apply RobustScaler\nspatial_shape = data_spatial.shape\ndata_spatial_reshaped = data_spatial.reshape(data_spatial.shape[0], -1) # Reshape data for RobustScaler (n_samples, n_features) format\ndata_spatial = scaler_spatial.fit_transform(data_spatial_reshaped)\ndata_spatial = data_spatial.reshape(spatial_shape) # Reshape back to original shape\nwith open(f\"{NAME}_spatial_scaler.pkl\", \"wb\") as f:\n    pickle.dump(scaler_spatial, f)\n\nscaler_temporal = RobustScaler() # Apply RobustScaler\ntemporal_shape = data_temporal.shape\ndata_temporal_reshaped = data_temporal.reshape(data_temporal.shape[0], -1) # Reshape data for RobustScaler (n_samples, n_features) format\ndata_temporal = scaler_temporal.fit_transform(data_temporal_reshaped)\ndata_temporal = data_temporal.reshape(temporal_shape) # Reshape back to original shape\nwith open(f\"{NAME}_temporal_scaler.pkl\", \"wb\") as f:\n    pickle.dump(scaler_temporal, f)\n\n# Add channel dimension\ndata_spatial = data_spatial[:, np.newaxis, :, :]\n\n###...............................Split into Training Validation and Test data...............................###\nX_spatial_train, X_spatial_test, X_temporal_train, X_temporal_test, stratify_train, stratify_test = (\n    train_test_split(\n        data_spatial,\n        data_temporal,\n        stratify,\n        test_size=TEST_SIZE,\n        random_state=SEED,\n        shuffle=True,\n        stratify=stratify,\n    )\n)\ny_train = stratify_train[:, 0]\ny_test = stratify_test[:, 0]\ndset_test = stratify_test[:, 1]\n\nX_spatial_train, X_spatial_val, X_temporal_train, X_temporal_val, y_train, y_val = (\n    train_test_split(\n        X_spatial_train,\n        X_temporal_train,\n        y_train,\n        test_size=TEST_SIZE,\n        random_state=SEED,\n        shuffle=True,\n        stratify=stratify_train,\n    )\n)\n\n\n###..................................Convert Data Tensors and move to the GPU..................................###\n# Convert to tensors and move to device\nX_spatial_train_tensor = torch.tensor(X_spatial_train, dtype=torch.float32).to(device)\nX_spatial_val_tensor = torch.tensor(X_spatial_val, dtype=torch.float32).to(device)\nX_spatial_test_tensor = torch.tensor(X_spatial_test, dtype=torch.float32).to(device)\n\nX_temporal_train_tensor = torch.tensor(X_temporal_train, dtype=torch.float32).to(device)\nX_temporal_val_tensor = torch.tensor(X_temporal_val, dtype=torch.float32).to(device)\nX_temporal_test_tensor = torch.tensor(X_temporal_test, dtype=torch.float32).to(device)\n\ny_train_tensor = torch.LongTensor(y_train).to(device)\ny_val_tensor = torch.LongTensor(y_val).to(device)\ny_test_tensor = torch.LongTensor(y_test).to(device)\n\n\n###.....................Create TensorDatasets for spatial and temporal inputs.....................###\ntrain_dataset = TensorDataset(X_spatial_train_tensor, X_temporal_train_tensor, y_train_tensor)\nval_dataset = TensorDataset(X_spatial_val_tensor, X_temporal_val_tensor, y_val_tensor)\ntest_dataset = TensorDataset(X_spatial_test_tensor, X_temporal_test_tensor, y_test_tensor)\n\n# Data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n###.........................Check label distribution for training.........................###\nunique, counts = np.unique(y_train_tensor.cpu(), return_counts=True)\nclass_distribution = dict(zip(unique, counts))\nprint(f\"y_train distribution: {class_distribution}\")\n\nunique, counts = np.unique(y_val_tensor.cpu(), return_counts=True)\nclass_distribution = dict(zip(unique, counts))\nprint(f\"y_val distribution: {class_distribution}\")\n\nunique, counts = np.unique(y_test_tensor.cpu(), return_counts=True)\nclass_distribution = dict(zip(unique, counts))\nprint(f\"y_test distribution: {class_distribution}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-29T16:03:57.775878Z","iopub.execute_input":"2024-09-29T16:03:57.776313Z","iopub.status.idle":"2024-09-29T16:04:11.119873Z","shell.execute_reply.started":"2024-09-29T16:03:57.776259Z","shell.execute_reply":"2024-09-29T16:04:11.118756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separate Test Loaders\nX_spatial_test_synth = X_spatial_test[dset_test == 0]\nX_temporal_test_synth = X_temporal_test[dset_test == 0]\ny_test_synth = y_test[dset_test == 0]\n\nX_spatial_test_whuref = X_spatial_test[dset_test == 1]\nX_temporal_test_whuref = X_temporal_test[dset_test == 1]\ny_test_whuref = y_test[dset_test == 1]\n\nX_spatial_test_carioca = X_spatial_test[dset_test == 2]\nX_temporal_test_carioca = X_temporal_test[dset_test == 2]\ny_test_carioca = y_test[dset_test == 2]\n\n# Convert to tensors and move to device\nX_spatial_test_synth = torch.tensor(X_spatial_test_synth, dtype=torch.float32).to(device)\nX_temporal_test_synth = torch.tensor(X_temporal_test_synth, dtype=torch.float32).to(device)\ny_test_synth = torch.LongTensor(y_test_synth).to(device)\n\nX_spatial_test_whuref = torch.tensor(X_spatial_test_whuref, dtype=torch.float32).to(device)\nX_temporal_test_whuref = torch.tensor(X_temporal_test_whuref, dtype=torch.float32).to(device)\ny_test_whuref = torch.LongTensor(y_test_whuref).to(device)\n\nX_spatial_test_carioca = torch.tensor(X_spatial_test_carioca, dtype=torch.float32).to(device)\nX_temporal_test_carioca = torch.tensor(X_temporal_test_carioca, dtype=torch.float32).to(device)\ny_test_carioca = torch.LongTensor(y_test_carioca).to(device)\n\n###.....................Create TensorDatasets for spatial and temporal inputs.....................###\ntest_dataset_synth = TensorDataset(X_spatial_test_synth, X_temporal_test_synth, y_test_synth)\ntest_dataset_whuref = TensorDataset(X_spatial_test_whuref, X_temporal_test_whuref, y_test_whuref)\ntest_dataset_carioca = TensorDataset(X_spatial_test_carioca, X_temporal_test_carioca, y_test_carioca)\n\n# Data loaders\ntest_loader_synth = DataLoader(test_dataset_synth, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader_whuref = DataLoader(test_dataset_whuref, batch_size=BATCH_SIZE, shuffle=False)\ntest_loader_carioca = DataLoader(test_dataset_carioca, batch_size=BATCH_SIZE, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T16:04:11.122387Z","iopub.execute_input":"2024-09-29T16:04:11.123008Z","iopub.status.idle":"2024-09-29T16:04:11.166541Z","shell.execute_reply.started":"2024-09-29T16:04:11.122958Z","shell.execute_reply":"2024-09-29T16:04:11.16566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss for binary classification\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  # Adam optimizer","metadata":{"execution":{"iopub.status.busy":"2024-09-29T15:30:02.97845Z","iopub.execute_input":"2024-09-29T15:30:02.978793Z","iopub.status.idle":"2024-09-29T15:30:03.989584Z","shell.execute_reply.started":"2024-09-29T15:30:02.978756Z","shell.execute_reply":"2024-09-29T15:30:03.988705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TRAINING","metadata":{}},{"cell_type":"code","source":"# Initialize EarlyStopping object\n# early_stopping = EarlyStopping(patience=100, min_delta=0.01)\n\n# Training and validation loop\ntrain_losses = []\nval_losses = []\ntrain_accuracies = []\nval_accuracies = []\n\nfor epoch in tqdm(range(NUM_EPOCHS), desc=\"Training Progress\"):\n    # Training\n    model.train()\n    train_loss = 0.0\n    correct_train = 0\n    total_train = 0\n    for spatial_inputs, temporal_inputs, labels in train_loader:  # Assuming data loader returns spatial and temporal inputs\n        optimizer.zero_grad()\n        outputs = model(spatial_inputs, temporal_inputs)\n        \n        # Ensure labels have the same shape as outputs\n        labels = labels.unsqueeze(1).float()  # Convert [64] to [64, 1]\n\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n\n        # Use sigmoid to get predictions for binary classification\n        predictions = torch.sigmoid(outputs)\n        predicted_labels = (predictions > 0.5).float()  # Convert to binary predictions\n        \n        total_train += labels.size(0)\n        correct_train += (predicted_labels == labels).sum().item()\n\n    train_loss /= len(train_loader)\n    train_losses.append(train_loss)\n    train_accuracy = correct_train / total_train\n    train_accuracies.append(train_accuracy)\n\n    # Validation\n    model.eval()\n    val_loss = 0.0\n    correct_val = 0\n    total_val = 0\n    with torch.no_grad():\n        for spatial_inputs, temporal_inputs, labels in val_loader:  # Assuming data loader returns spatial and temporal inputs\n            outputs = model(spatial_inputs, temporal_inputs)\n            \n            # Ensure labels have the same shape as outputs\n            labels = labels.unsqueeze(1).float()  # Convert [64] to [64, 1]\n\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n            # Use sigmoid to get predictions for binary classification\n            predictions = torch.sigmoid(outputs)\n            predicted_labels = (predictions > 0.5).float()  # Convert to binary predictions\n\n            total_val += labels.size(0)\n            correct_val += (predicted_labels == labels).sum().item()\n\n    val_loss /= len(val_loader)\n    val_losses.append(val_loss)\n    val_accuracy = correct_val / total_val\n    val_accuracies.append(val_accuracy)\n\n    tqdm.write(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n    \n    # # Check early stopping condition\n    # early_stopping(val_loss)\n    # if early_stopping.early_stop:\n    #     print(\"Early stopping\")\n    #     break","metadata":{"execution":{"iopub.status.busy":"2024-09-29T15:30:03.99169Z","iopub.execute_input":"2024-09-29T15:30:03.992217Z","iopub.status.idle":"2024-09-29T15:34:32.370114Z","shell.execute_reply.started":"2024-09-29T15:30:03.992165Z","shell.execute_reply":"2024-09-29T15:34:32.369106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TESTING","metadata":{}},{"cell_type":"code","source":"## Synthetische Daten\n\n# Testing phase\nmodel.eval()\ntest_loss = 0.0\ncorrect = 0\ntotal = 0\ntrue_positive = 0\nfalse_positive = 0\nfalse_negative = 0\ntrue_negative = 0  # For untampered sample recall\n\n# Confusion matrix elements\nconfusion_matrix = torch.zeros(2, 2)  # 2x2 for binary classification\n\nwith torch.no_grad():\n    for spatial_inputs, temporal_inputs, labels in test_loader_synth:  # Assuming data loader returns spatial and temporal inputs\n        outputs = model(spatial_inputs, temporal_inputs)\n        \n        labels = labels.unsqueeze(1).float()  # Adjust labels to match the output dimension\n        \n        loss = criterion(outputs, labels)\n        test_loss += loss.item()\n        \n        predictions = torch.sigmoid(outputs)\n        predicted_labels = (predictions > 0.5).float()  # Convert to binary labels\n        \n        total += labels.size(0)\n        correct += (predicted_labels == labels).sum().item()\n        \n        # Update confusion matrix\n        for t, p in zip(labels.view(-1), predicted_labels.view(-1)):  # Iterate over true and predicted labels\n            confusion_matrix[int(t.long()), int(p.long())] += 1  # Fill confusion matrix\n        \n        # Calculate True Positives, False Positives, False Negatives, and True Negatives\n        true_positive += ((predicted_labels == 1) & (labels == 1)).sum().item()\n        false_positive += ((predicted_labels == 1) & (labels == 0)).sum().item()\n        false_negative += ((predicted_labels == 0) & (labels == 1)).sum().item()\n        true_negative += ((predicted_labels == 0) & (labels == 0)).sum().item()\n\ntest_loss /= len(test_loader_synth)\ntest_accuracy = correct / total\n\n# Calculate Precision\nif true_positive + false_positive > 0:\n    precision = true_positive / (true_positive + false_positive)\nelse:\n    precision = 0.0  # Avoid division by zero\n\n# Calculate Recall for tampered samples (positive class)\nif true_positive + false_negative > 0:\n    recall_tampered = true_positive / (true_positive + false_negative)\nelse:\n    recall_tampered = 0.0  # Avoid division by zero\n\n# Calculate Recall for untampered samples (negative class)\nif true_negative + false_positive > 0:\n    recall_untampered = true_negative / (true_negative + false_positive)\nelse:\n    recall_untampered = 0.0  # Avoid division by zero\n\n# Print results\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Precision: {precision:.4f}, Test Recall (tampered): {recall_tampered:.4f}, Test Recall (untampered): {recall_untampered:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-29T16:04:23.930003Z","iopub.execute_input":"2024-09-29T16:04:23.930902Z","iopub.status.idle":"2024-09-29T16:04:24.08235Z","shell.execute_reply.started":"2024-09-29T16:04:23.93086Z","shell.execute_reply":"2024-09-29T16:04:24.081361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training and validation losses and accuracies\nplt.figure(figsize=(12, 6))\n\n# Plotting Training and Validation Loss\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label=\"Train Loss\", alpha=0.7)\nplt.plot(val_losses, label=\"Validation Loss\", alpha=0.7)\nplt.xlabel(\"Epoche\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.title(\"Training and Validation Loss\")\n\n# Plotting Training and Validation Accuracy\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracies, label=\"Train Accuracy\", alpha=0.7)\nplt.plot(val_accuracies, label=\"Validation Accuracy\", alpha=0.7)\nplt.xlabel(\"Epoche\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title(\"Training und Validation Accuracy\")\nplt.savefig('Valdidation_accuracy_and_loss_cnn-bilstm_all_freqs.pdf', dpi=300)\nplt.tight_layout()\nplt.show()\n\n\n# Convert confusion matrix to numpy for plotting\ncm = confusion_matrix.numpy()\n\n# Plotting the confusion matrix using seaborn\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, fmt='.0f', cmap='Blues', xticklabels=['Ungeschnitten', 'Geschnitten'], yticklabels=['Ungeschnitten', 'Geschnitten'])\nplt.xlabel('Vorhergesagtes Label')\nplt.ylabel('Wahres Label')\nplt.title('Confusion Matrix')\nplt.savefig('synth_confusion_matrix_cnn-bilstm_all_freqs.pdf', dpi=300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-29T16:04:33.149957Z","iopub.execute_input":"2024-09-29T16:04:33.150451Z","iopub.status.idle":"2024-09-29T16:04:34.752399Z","shell.execute_reply.started":"2024-09-29T16:04:33.150408Z","shell.execute_reply":"2024-09-29T16:04:34.751421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## WHU Ref Data\nprint(\"WHU_ref\")\n\n# Testing phase\nmodel.eval()\ntest_loss = 0.0\ncorrect = 0\ntotal = 0\ntrue_positive = 0\nfalse_positive = 0\nfalse_negative = 0\ntrue_negative = 0  # For untampered sample recall\n\n# Confusion matrix elements\nconfusion_matrix = torch.zeros(2, 2)  # 2x2 for binary classification\n\nwith torch.no_grad():\n    for spatial_inputs, temporal_inputs, labels in test_loader_whuref:  # Assuming data loader returns spatial and temporal inputs\n        outputs = model(spatial_inputs, temporal_inputs)\n        \n        labels = labels.unsqueeze(1).float()  # Adjust labels to match the output dimension\n        \n        loss = criterion(outputs, labels)\n        test_loss += loss.item()\n        \n        predictions = torch.sigmoid(outputs)\n        predicted_labels = (predictions > 0.5).float()  # Convert to binary labels\n        \n        total += labels.size(0)\n        correct += (predicted_labels == labels).sum().item()\n        \n        # Update confusion matrix\n        for t, p in zip(labels.view(-1), predicted_labels.view(-1)):  # Iterate over true and predicted labels\n            confusion_matrix[int(t.long()), int(p.long())] += 1  # Fill confusion matrix\n        \n        # Calculate True Positives, False Positives, False Negatives, and True Negatives\n        true_positive += ((predicted_labels == 1) & (labels == 1)).sum().item()\n        false_positive += ((predicted_labels == 1) & (labels == 0)).sum().item()\n        false_negative += ((predicted_labels == 0) & (labels == 1)).sum().item()\n        true_negative += ((predicted_labels == 0) & (labels == 0)).sum().item()\n\ntest_loss /= len(test_loader_whuref)\ntest_accuracy = correct / total\n\n# Calculate Precision\nif true_positive + false_positive > 0:\n    precision = true_positive / (true_positive + false_positive)\nelse:\n    precision = 0.0  # Avoid division by zero\n\n# Calculate Recall for tampered samples (positive class)\nif true_positive + false_negative > 0:\n    recall_tampered = true_positive / (true_positive + false_negative)\nelse:\n    recall_tampered = 0.0  # Avoid division by zero\n\n# Calculate Recall for untampered samples (negative class)\nif true_negative + false_positive > 0:\n    recall_untampered = true_negative / (true_negative + false_positive)\nelse:\n    recall_untampered = 0.0  # Avoid division by zero\n\n# Print results\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Precision: {precision:.4f}, Test Recall (tampered): {recall_tampered:.4f}, Test Recall (untampered): {recall_untampered:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-29T16:08:46.464029Z","iopub.execute_input":"2024-09-29T16:08:46.464419Z","iopub.status.idle":"2024-09-29T16:08:46.561793Z","shell.execute_reply.started":"2024-09-29T16:08:46.464382Z","shell.execute_reply":"2024-09-29T16:08:46.560869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert confusion matrix to numpy for plotting\ncm = confusion_matrix.numpy()\n\n# Plotting the confusion matrix using seaborn\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, fmt='.0f', cmap='Blues', xticklabels=['Ungeschnitten', 'Geschnitten'], yticklabels=['Ungeschnitten', 'Geschnitten'])\nplt.xlabel('Vorhergesagtes Label')\nplt.ylabel('Wahres Label')\nplt.title('Confusion Matrix WHU_ref')\nplt.savefig('whuref_confusion_matrix_cnn-bilstm_all_freqs.pdf', dpi=300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-29T16:08:55.563233Z","iopub.execute_input":"2024-09-29T16:08:55.563935Z","iopub.status.idle":"2024-09-29T16:08:55.886528Z","shell.execute_reply.started":"2024-09-29T16:08:55.563895Z","shell.execute_reply":"2024-09-29T16:08:55.885282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Carioca Data\nprint(\"Carioca\")\n\n# Testing phase\nmodel.eval()\ntest_loss = 0.0\ncorrect = 0\ntotal = 0\ntrue_positive = 0\nfalse_positive = 0\nfalse_negative = 0\ntrue_negative = 0  # For untampered sample recall\n\n# Confusion matrix elements\nconfusion_matrix = torch.zeros(2, 2)  # 2x2 for binary classification\n\nwith torch.no_grad():\n    for spatial_inputs, temporal_inputs, labels in test_loader_carioca:  # Assuming data loader returns spatial and temporal inputs\n        outputs = model(spatial_inputs, temporal_inputs)\n        \n        labels = labels.unsqueeze(1).float()  # Adjust labels to match the output dimension\n        \n        loss = criterion(outputs, labels)\n        test_loss += loss.item()\n        \n        predictions = torch.sigmoid(outputs)\n        predicted_labels = (predictions > 0.5).float()  # Convert to binary labels\n        \n        total += labels.size(0)\n        correct += (predicted_labels == labels).sum().item()\n        \n        # Update confusion matrix\n        for t, p in zip(labels.view(-1), predicted_labels.view(-1)):  # Iterate over true and predicted labels\n            confusion_matrix[int(t.long()), int(p.long())] += 1  # Fill confusion matrix\n        \n        # Calculate True Positives, False Positives, False Negatives, and True Negatives\n        true_positive += ((predicted_labels == 1) & (labels == 1)).sum().item()\n        false_positive += ((predicted_labels == 1) & (labels == 0)).sum().item()\n        false_negative += ((predicted_labels == 0) & (labels == 1)).sum().item()\n        true_negative += ((predicted_labels == 0) & (labels == 0)).sum().item()\n\ntest_loss /= len(test_loader_carioca)\ntest_accuracy = correct / total\n\n# Calculate Precision\nif true_positive + false_positive > 0:\n    precision = true_positive / (true_positive + false_positive)\nelse:\n    precision = 0.0  # Avoid division by zero\n\n# Calculate Recall for tampered samples (positive class)\nif true_positive + false_negative > 0:\n    recall_tampered = true_positive / (true_positive + false_negative)\nelse:\n    recall_tampered = 0.0  # Avoid division by zero\n\n# Calculate Recall for untampered samples (negative class)\nif true_negative + false_positive > 0:\n    recall_untampered = true_negative / (true_negative + false_positive)\nelse:\n    recall_untampered = 0.0  # Avoid division by zero\n\n# Print results\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Precision: {precision:.4f}, Test Recall (tampered): {recall_tampered:.4f}, Test Recall (untampered): {recall_untampered:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-29T16:08:26.023388Z","iopub.execute_input":"2024-09-29T16:08:26.023782Z","iopub.status.idle":"2024-09-29T16:08:26.155989Z","shell.execute_reply.started":"2024-09-29T16:08:26.023747Z","shell.execute_reply":"2024-09-29T16:08:26.155149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Plot Carioca confusion matrix\n# Convert confusion matrix to numpy for plotting\ncm = confusion_matrix.numpy()\n\n# Plotting the confusion matrix using seaborn\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, fmt='.0f', cmap='Blues', xticklabels=['Ungeschnitten', 'Geschnitten'], yticklabels=['Ungeschnitten', 'Geschnitten'])\nplt.xlabel('Vorhergesagtes Label')\nplt.ylabel('Wahres Label')\nplt.title('Confusion Matrix Carioca')\nplt.savefig('carioca_confusion_matrix_cnn-bilstm_all_freqs.pdf', dpi=300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-29T16:08:12.628425Z","iopub.execute_input":"2024-09-29T16:08:12.628827Z","iopub.status.idle":"2024-09-29T16:08:13.119398Z","shell.execute_reply.started":"2024-09-29T16:08:12.628791Z","shell.execute_reply":"2024-09-29T16:08:13.118285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## All\nprint(\"Alldata\")\n\n# Testing phase\nmodel.eval()\ntest_loss = 0.0\ncorrect = 0\ntotal = 0\ntrue_positive = 0\nfalse_positive = 0\nfalse_negative = 0\ntrue_negative = 0  # For untampered sample recall\n\n# Confusion matrix elements\nconfusion_matrix = torch.zeros(2, 2)  # 2x2 for binary classification\n\nwith torch.no_grad():\n    for spatial_inputs, temporal_inputs, labels in test_loader:  # Assuming data loader returns spatial and temporal inputs\n        outputs = model(spatial_inputs, temporal_inputs)\n        \n        labels = labels.unsqueeze(1).float()  # Adjust labels to match the output dimension\n        \n        loss = criterion(outputs, labels)\n        test_loss += loss.item()\n        \n        predictions = torch.sigmoid(outputs)\n        predicted_labels = (predictions > 0.5).float()  # Convert to binary labels\n        \n        total += labels.size(0)\n        correct += (predicted_labels == labels).sum().item()\n        \n        # Update confusion matrix\n        for t, p in zip(labels.view(-1), predicted_labels.view(-1)):  # Iterate over true and predicted labels\n            confusion_matrix[int(t.long()), int(p.long())] += 1  # Fill confusion matrix\n        \n        # Calculate True Positives, False Positives, False Negatives, and True Negatives\n        true_positive += ((predicted_labels == 1) & (labels == 1)).sum().item()\n        false_positive += ((predicted_labels == 1) & (labels == 0)).sum().item()\n        false_negative += ((predicted_labels == 0) & (labels == 1)).sum().item()\n        true_negative += ((predicted_labels == 0) & (labels == 0)).sum().item()\n\ntest_loss /= len(test_loader_carioca)\ntest_accuracy = correct / total\n\n# Calculate Precision\nif true_positive + false_positive > 0:\n    precision = true_positive / (true_positive + false_positive)\nelse:\n    precision = 0.0  # Avoid division by zero\n\n# Calculate Recall for tampered samples (positive class)\nif true_positive + false_negative > 0:\n    recall_tampered = true_positive / (true_positive + false_negative)\nelse:\n    recall_tampered = 0.0  # Avoid division by zero\n\n# Calculate Recall for untampered samples (negative class)\nif true_negative + false_positive > 0:\n    recall_untampered = true_negative / (true_negative + false_positive)\nelse:\n    recall_untampered = 0.0  # Avoid division by zero\n\n# Print results\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Precision: {precision:.4f}, Test Recall (tampered): {recall_tampered:.4f}, Test Recall (untampered): {recall_untampered:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-29T16:06:44.474327Z","iopub.execute_input":"2024-09-29T16:06:44.475142Z","iopub.status.idle":"2024-09-29T16:06:44.797108Z","shell.execute_reply.started":"2024-09-29T16:06:44.475103Z","shell.execute_reply":"2024-09-29T16:06:44.796114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Plot Carioca confusion matrix\n# Convert confusion matrix to numpy for plotting\ncm = confusion_matrix.numpy()\n\n# Plotting the confusion matrix using seaborn\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, fmt='.0f', cmap='Blues', xticklabels=['Ungeschnitten', 'Geschnitten'], yticklabels=['Ungeschnitten', 'Geschnitten'])\nplt.xlabel('Vorhergesagtes Label')\nplt.ylabel('Wahres Label')\nplt.title('Confusion Matrix All Data')\nplt.savefig('carioca_confusion_matrix_cnn-bilstm_all_freqs.pdf', dpi=300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-29T16:07:52.031392Z","iopub.execute_input":"2024-09-29T16:07:52.031781Z","iopub.status.idle":"2024-09-29T16:07:52.345131Z","shell.execute_reply.started":"2024-09-29T16:07:52.031746Z","shell.execute_reply":"2024-09-29T16:07:52.343884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model\ntorch.save(model.state_dict(), f\"{NAME}_model.pth\")\nprint(\"Model saved successfully!\")","metadata":{"execution":{"iopub.status.busy":"2024-09-29T16:04:42.861517Z","iopub.execute_input":"2024-09-29T16:04:42.861902Z","iopub.status.idle":"2024-09-29T16:04:42.892082Z","shell.execute_reply.started":"2024-09-29T16:04:42.861862Z","shell.execute_reply":"2024-09-29T16:04:42.891141Z"},"trusted":true},"execution_count":null,"outputs":[]}]}